{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0968a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/setone/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/setone/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/setone/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/setone/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "# numericalization\n",
    "from collections import Counter\n",
    "\n",
    "# preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # will give an altered version later cuz the default isn't great\n",
    "from string import punctuation\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# neural nets\n",
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras import Sequential, Input, optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "title_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d628f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/StockTwits_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860c11c",
   "metadata": {},
   "source": [
    "### Cleaning up the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9924d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = df['raw_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6687c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substring(string, pattern, replacement=''):\n",
    "    \n",
    "    substrings_to_remove = re.findall(pattern, string)\n",
    "    for substring in substrings_to_remove:\n",
    "        string = string.replace(substring, replacement)\n",
    "        \n",
    "    return string\n",
    "\n",
    "def reduce_repeated_chars(string):\n",
    "    new_string = ''\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "        j = i + 1\n",
    "        while j < len(string) and string[j] == string[i]:\n",
    "            j += 1\n",
    "        new_string += string[i] + (string[i] if j - i >= 2 else '')\n",
    "        i = j\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05411371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making everything lowercase\n",
    "df['body'] = df['body'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f3708f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing patterns\n",
    "\n",
    "website_pattern = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "numbers = '\\d+'\n",
    "usernames = '@[^\\s]+'\n",
    "tickers = '\\$[^\\s]+'\n",
    "extra_spaces = '  +'\n",
    "hashtags = '\\$[^\\s]+'\n",
    "next_lines = '\\\\n'\n",
    "\n",
    "\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, website_pattern))\n",
    "df['body'] = df['body'].apply(lambda x: x.encode('ascii', 'ignore').decode()) #emojis\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, usernames))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, tickers))\n",
    "df['body'] = df['body'].apply(lambda x: reduce_repeated_chars(x))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, numbers))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, hashtags))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, next_lines, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d0cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~‘’“”1234567890…ðŸ‘‰ðŸ‘ŒðŸ’¦âœ¨✰♡*•˛❤•\n"
     ]
    }
   ],
   "source": [
    "# removing all punctuation\n",
    "\n",
    "punct = punctuation + '‘’“”1234567890…ðŸ‘‰ðŸ‘ŒðŸ’¦âœ¨✰♡*•˛❤•'\n",
    "print(punct)\n",
    "df['body'] = df['body'].apply(lambda x: ''.join([c for c in x if c not in punct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f52e7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words \n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', \n",
    "             'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
    "             'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', \n",
    "             'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', \n",
    "             'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \n",
    "             'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "             'after', 'to', 'from', 'in', 'out', 'on', 'off', 'again', 'further', 'then', 'once', 'here', 'there', \n",
    "             'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "             'such', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', \n",
    "             'don', 'dont', 'should', 'shouldve', 'now', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', \n",
    "             'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', \n",
    "             'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', \n",
    "             'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt']\n",
    "\n",
    "df['body'] = df['body'].apply(lambda x: ' '.join(x for x in x.split() if x not in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe282d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finishing up by removing extra spaces\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, extra_spaces, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "437e8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with just white spaces\n",
    "df = df[~(df['body'].str.contains('^\\s$', regex=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22ee82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any rows with just one word wont provide enough context, so we'll remove them as well\n",
    "df = df[(df['body'].str.contains(' '))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec035d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-15T14:40:00Z</td>\n",
       "      <td>moving fast early</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL Moving fast early!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-15T14:39:57Z</td>\n",
       "      <td>confirms daily rip</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL if confirms daily can rip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-15T14:39:42Z</td>\n",
       "      <td>word got miss chance</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL word got out .... don’t miss your chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-15T14:39:40Z</td>\n",
       "      <td>sold weeklies early lol</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL who sold there weeklies to early lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-15T14:39:36Z</td>\n",
       "      <td>another walk lets see gets gobbled up</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL another walk at 126 let’s see if it gets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at                                   body  sentiment  \\\n",
       "0  2020-12-15T14:40:00Z                      moving fast early          1   \n",
       "1  2020-12-15T14:39:57Z                     confirms daily rip          1   \n",
       "2  2020-12-15T14:39:42Z                   word got miss chance          1   \n",
       "3  2020-12-15T14:39:40Z                sold weeklies early lol          1   \n",
       "4  2020-12-15T14:39:36Z  another walk lets see gets gobbled up          1   \n",
       "\n",
       "                                         raw_content  \n",
       "0                           $AAPL Moving fast early!  \n",
       "1                    $AAPL if confirms daily can rip  \n",
       "2     $AAPL word got out .... don’t miss your chance  \n",
       "3         $AAPL who sold there weeklies to early lol  \n",
       "4  $AAPL another walk at 126 let’s see if it gets...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66699b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take ~24 hours\n",
    "# # correct spellings\n",
    "\n",
    "# def spelling_check(text):\n",
    "#     global idx\n",
    "    \n",
    "#     idx += 1\n",
    "    \n",
    "#     if idx % 1e3 == 0: print(idx)\n",
    "        \n",
    "#     try:\n",
    "#         result = str(TextBlob(text).correct())\n",
    "#     except:\n",
    "#         print(f'failed at {idx}')\n",
    "        \n",
    "#     return result\n",
    "\n",
    "# idx = 0\n",
    "# df['body'] = df['body'].apply(lambda x: spelling_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1542ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862570, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsetting a random sample of positive and negative to create a balanced dataset\n",
    "\n",
    "df_negative = df[df['sentiment'] == 0]\n",
    "df_positive = df.query(\"sentiment == 1\").sample(n=len(df_negative))\n",
    "\n",
    "df = pd.concat([df_negative, df_positive])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e3c0e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-12-15T14:38:18Z</td>\n",
       "      <td>going right support even superior growth trade</td>\n",
       "      <td>0</td>\n",
       "      <td>$MSFT Going right through 214 support as if it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-12-15T14:23:04Z</td>\n",
       "      <td>nobody gonna buy expensive ass iphones aint go...</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL nobody gonna buy expensive ass iPhones w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2020-12-15T14:12:10Z</td>\n",
       "      <td>robinhood peeps gonna severely disappointed tu...</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL Robinhood peeps gonna be severely disapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-12-15T13:33:52Z</td>\n",
       "      <td>always dump dump dump</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL always dump dump dump.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2020-12-15T13:30:10Z</td>\n",
       "      <td>turd going anywhere pathetic</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL why is this turd not going anywhere. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942436</th>\n",
       "      <td>2021-05-11T12:36:16Z</td>\n",
       "      <td>january calls look really good totally buying ...</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA $NIO $LI $XPEV \\n\\nJanuary 2023 calls lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212986</th>\n",
       "      <td>2021-03-25T22:44:46Z</td>\n",
       "      <td>joe ohm raised price target</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA joe ohm raised price target from $800 to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900463</th>\n",
       "      <td>2020-01-22T19:31:24Z</td>\n",
       "      <td>like people discovered electric cars first tim...</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA It’s like people have just discovered el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213039</th>\n",
       "      <td>2021-03-25T21:05:38Z</td>\n",
       "      <td>yes baby yes</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA Yes baby yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066456</th>\n",
       "      <td>2021-02-02T04:59:39Z</td>\n",
       "      <td>already announced new sedan model due late yea...</td>\n",
       "      <td>1</td>\n",
       "      <td>$LI already announced the new sedan model due ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>862570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at  \\\n",
       "14       2020-12-15T14:38:18Z   \n",
       "49       2020-12-15T14:23:04Z   \n",
       "61       2020-12-15T14:12:10Z   \n",
       "103      2020-12-15T13:33:52Z   \n",
       "106      2020-12-15T13:30:10Z   \n",
       "...                       ...   \n",
       "1942436  2021-05-11T12:36:16Z   \n",
       "1212986  2021-03-25T22:44:46Z   \n",
       "1900463  2020-01-22T19:31:24Z   \n",
       "1213039  2021-03-25T21:05:38Z   \n",
       "1066456  2021-02-02T04:59:39Z   \n",
       "\n",
       "                                                      body  sentiment  \\\n",
       "14          going right support even superior growth trade          0   \n",
       "49       nobody gonna buy expensive ass iphones aint go...          0   \n",
       "61       robinhood peeps gonna severely disappointed tu...          0   \n",
       "103                                  always dump dump dump          0   \n",
       "106                           turd going anywhere pathetic          0   \n",
       "...                                                    ...        ...   \n",
       "1942436  january calls look really good totally buying ...          1   \n",
       "1212986                        joe ohm raised price target          1   \n",
       "1900463  like people discovered electric cars first tim...          1   \n",
       "1213039                                       yes baby yes          1   \n",
       "1066456  already announced new sedan model due late yea...          1   \n",
       "\n",
       "                                               raw_content  \n",
       "14       $MSFT Going right through 214 support as if it...  \n",
       "49       $AAPL nobody gonna buy expensive ass iPhones w...  \n",
       "61       $AAPL Robinhood peeps gonna be severely disapp...  \n",
       "103                           $AAPL always dump dump dump.  \n",
       "106      $AAPL why is this turd not going anywhere. Thi...  \n",
       "...                                                    ...  \n",
       "1942436  $TSLA $NIO $LI $XPEV \\n\\nJanuary 2023 calls lo...  \n",
       "1212986  $TSLA joe ohm raised price target from $800 to...  \n",
       "1900463  $TSLA It’s like people have just discovered el...  \n",
       "1213039                                 $TSLA Yes baby yes  \n",
       "1066456  $LI already announced the new sedan model due ...  \n",
       "\n",
       "[862570 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "df['body'] = df['body'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68a0dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/balanced_untokenized_cleaned_stocktwits.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea6867",
   "metadata": {},
   "source": [
    "### Lemmatization + Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "257286b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 100000 complete\n",
      "row 200000 complete\n",
      "row 300000 complete\n",
      "row 400000 complete\n",
      "row 500000 complete\n",
      "row 600000 complete\n",
      "row 700000 complete\n",
      "row 800000 complete\n"
     ]
    }
   ],
   "source": [
    "# tokenization + lemmatization \n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "idx = 0\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    global idx\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "    if idx % 1e5 == 0: print(f'row {idx} complete')\n",
    "        \n",
    "    try: \n",
    "        result = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    except:\n",
    "        print(f'failed at {idx}')\n",
    "        \n",
    "    return result\n",
    "\n",
    "df['body'] = df['body'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "216d072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/balanced_lemmatized_cleaned_stocktwits.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d19a02",
   "metadata": {},
   "source": [
    "### Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0da991d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "corpus = df['body'].values\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "763c70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an int-mapping dictionary\n",
    "vocab_to_int = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e606e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "padded_sequences = pad_sequences(sequences, max_words, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "425e7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = max(df['body'].str.len())\n",
    "padded_sequences = pad_sequences(sequences, max_words, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1788ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(padded_sequences)\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18515747",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ca569c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('./data/padded_X.csv', index_label=False)\n",
    "y.to_csv('./data/padded_y.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428f8ec",
   "metadata": {},
   "source": [
    "### Create Preprocessing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332aca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substring(string, pattern, replacement=''):\n",
    "    \n",
    "    substrings_to_remove = re.findall(pattern, string)\n",
    "    for substring in substrings_to_remove:\n",
    "        string = string.replace(substring, replacement)\n",
    "        \n",
    "    return string\n",
    "\n",
    "def reduce_repeated_chars(string):\n",
    "    new_string = ''\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "        j = i + 1\n",
    "        while j < len(string) and string[j] == string[i]:\n",
    "            j += 1\n",
    "        new_string += string[i] + (string[i] if j - i >= 2 else '')\n",
    "        i = j\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c219e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "websites = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "numbers = '\\d+'\n",
    "usernames = '@[^\\s]+'\n",
    "tickers = '\\$[^\\s]+'\n",
    "extra_spaces = '  +'\n",
    "hashtags = '\\$[^\\s]+'\n",
    "next_lines = '\\\\n'\n",
    "\n",
    "punctuation = \"!#$%&'()*+,-./:;<=>?@[\\]^_`{|}~‘’“”1234567890…ðŸ‘‰ðŸ‘ŒðŸ’¦âœ¨✰♡*•˛❤•\" + '\"'\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', \n",
    "             'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
    "             'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', \n",
    "             'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', \n",
    "             'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \n",
    "             'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "             'after', 'to', 'from', 'in', 'out', 'on', 'off', 'again', 'further', 'then', 'once', 'here', 'there', \n",
    "             'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "             'such', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', \n",
    "             'don', 'dont', 'should', 'shouldve', 'now', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', \n",
    "             'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', \n",
    "             'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', \n",
    "             'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef78cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    '''\n",
    "    preprocess the text to input into model\n",
    "    '''\n",
    "    \n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # make texts lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove websites and usernames, if exist\n",
    "    text = re.sub(websites, '', text)\n",
    "    text = re.sub(usernames, '', text)\n",
    "    text = re.sub(numbers, '', text)\n",
    "    text = re.sub(tickers, '', text)\n",
    "    text = re.sub(hashtags, '', text)\n",
    "    text = re.sub(next_lines, '', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = ''.join([x for x in text if x not in punctuation])\n",
    "    \n",
    "    # remove stop words\n",
    "    text = ' '.join(text.lower() for text in text.split() if text not in stopwords)\n",
    "    \n",
    "    # remove additional spaces\n",
    "    text = re.sub(extra_spaces, '', text)\n",
    "    \n",
    "    # lemmatize & tokenize\n",
    "    text = [lemmatizer.lemmatize(x) for x in w_tokenizer.tokenize(text)]\n",
    "    \n",
    "    # numericalize\n",
    "    text_int = []\n",
    "    text_int.append([dct[word] for word in text])\n",
    "    \n",
    "    return text_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ea7346c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m pad_sequences(\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m31\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[78], line 34\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# numericalize\u001b[39;00m\n\u001b[1;32m     33\u001b[0m text_int \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 34\u001b[0m text_int\u001b[38;5;241m.\u001b[39mappend([dct[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_int\n",
      "Cell \u001b[0;32mIn[78], line 34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# numericalize\u001b[39;00m\n\u001b[1;32m     33\u001b[0m text_int \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 34\u001b[0m text_int\u001b[38;5;241m.\u001b[39mappend([\u001b[43mdct\u001b[49m[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_int\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dct' is not defined"
     ]
    }
   ],
   "source": [
    "text = 'hello'\n",
    "pad_sequences(preprocess(text), 31, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08d4b1be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'up': 1,\n",
       " 'today': 2,\n",
       " 'down': 3,\n",
       " 'buy': 4,\n",
       " 'going': 5,\n",
       " 'go': 6,\n",
       " 'tomorrow': 7,\n",
       " 'like': 8,\n",
       " 'get': 9,\n",
       " 'tesla': 10,\n",
       " 'day': 11,\n",
       " 'market': 12,\n",
       " 'back': 13,\n",
       " 'bears': 14,\n",
       " 'puts': 15,\n",
       " 'next': 16,\n",
       " 'stock': 17,\n",
       " 'see': 18,\n",
       " 'short': 19,\n",
       " 'bulls': 20,\n",
       " 'sell': 21,\n",
       " 'week': 22,\n",
       " 'time': 23,\n",
       " 'no': 24,\n",
       " 'calls': 25,\n",
       " 'lol': 26,\n",
       " 'good': 27,\n",
       " 'lets': 28,\n",
       " 'over': 29,\n",
       " 'money': 30,\n",
       " 'im': 31,\n",
       " 'elon': 32,\n",
       " 'coming': 33,\n",
       " 'still': 34,\n",
       " 'big': 35,\n",
       " 'buying': 36,\n",
       " 'price': 37,\n",
       " 'long': 38,\n",
       " 'green': 39,\n",
       " 'close': 40,\n",
       " 'one': 41,\n",
       " 'red': 42,\n",
       " 'think': 43,\n",
       " 'gonna': 44,\n",
       " 'soon': 45,\n",
       " 'dip': 46,\n",
       " 'apple': 47,\n",
       " 'bought': 48,\n",
       " 'shares': 49,\n",
       " 'drop': 50,\n",
       " 'new': 51,\n",
       " 'last': 52,\n",
       " 'news': 53,\n",
       " 'people': 54,\n",
       " 'come': 55,\n",
       " 'earnings': 56,\n",
       " 'right': 57,\n",
       " 'would': 58,\n",
       " 'hold': 59,\n",
       " 'selling': 60,\n",
       " 'way': 61,\n",
       " 'run': 62,\n",
       " 'open': 63,\n",
       " 'shorts': 64,\n",
       " 'take': 65,\n",
       " 'make': 66,\n",
       " 'even': 67,\n",
       " 'got': 68,\n",
       " 'know': 69,\n",
       " 'looking': 70,\n",
       " 'cant': 71,\n",
       " 'company': 72,\n",
       " 'keep': 73,\n",
       " 'another': 74,\n",
       " 'end': 75,\n",
       " 'break': 76,\n",
       " 'need': 77,\n",
       " 'look': 78,\n",
       " 'sold': 79,\n",
       " 'bullish': 80,\n",
       " 'much': 81,\n",
       " 'call': 82,\n",
       " 'below': 83,\n",
       " 'looks': 84,\n",
       " 's': 85,\n",
       " 'wait': 86,\n",
       " 'year': 87,\n",
       " 'holding': 88,\n",
       " 'tsla': 89,\n",
       " 'k': 90,\n",
       " 'bear': 91,\n",
       " 'bull': 92,\n",
       " 'well': 93,\n",
       " 'friday': 94,\n",
       " 'high': 95,\n",
       " 'great': 96,\n",
       " 'getting': 97,\n",
       " 'could': 98,\n",
       " 'guys': 99,\n",
       " 'shit': 100,\n",
       " 'dump': 101,\n",
       " 'us': 102,\n",
       " 'want': 103,\n",
       " 'monday': 104,\n",
       " 'days': 105,\n",
       " 'put': 106,\n",
       " 'ready': 107,\n",
       " 'nice': 108,\n",
       " 'stocks': 109,\n",
       " 'goes': 110,\n",
       " 'pump': 111,\n",
       " 'love': 112,\n",
       " 'split': 113,\n",
       " 'never': 114,\n",
       " 'er': 115,\n",
       " 'morning': 116,\n",
       " 'under': 117,\n",
       " 'watch': 118,\n",
       " 'move': 119,\n",
       " 'stop': 120,\n",
       " 'already': 121,\n",
       " 'gap': 122,\n",
       " 'thats': 123,\n",
       " 'many': 124,\n",
       " 'bad': 125,\n",
       " 'target': 126,\n",
       " 'hit': 127,\n",
       " 'better': 128,\n",
       " 'let': 129,\n",
       " 'hope': 130,\n",
       " 'really': 131,\n",
       " 'everyone': 132,\n",
       " 'musk': 133,\n",
       " 'bearish': 134,\n",
       " 'bounce': 135,\n",
       " 'volume': 136,\n",
       " 'lower': 137,\n",
       " 'huge': 138,\n",
       " 'support': 139,\n",
       " 'low': 140,\n",
       " 'top': 141,\n",
       " 'term': 142,\n",
       " 'tech': 143,\n",
       " 'wow': 144,\n",
       " 'higher': 145,\n",
       " 'above': 146,\n",
       " 'hard': 147,\n",
       " 'thing': 148,\n",
       " 'yesterday': 149,\n",
       " 'amp': 150,\n",
       " 'every': 151,\n",
       " 'chart': 152,\n",
       " 'say': 153,\n",
       " 'crash': 154,\n",
       " 'easy': 155,\n",
       " 'trap': 156,\n",
       " 'said': 157,\n",
       " 'please': 158,\n",
       " 'may': 159,\n",
       " 'profit': 160,\n",
       " 'around': 161,\n",
       " 'strong': 162,\n",
       " 'oh': 163,\n",
       " 'u': 164,\n",
       " 'eod': 165,\n",
       " 'might': 166,\n",
       " 'trading': 167,\n",
       " 'ill': 168,\n",
       " 'amazon': 169,\n",
       " 'real': 170,\n",
       " 'profits': 171,\n",
       " 'anyone': 172,\n",
       " 'baby': 173,\n",
       " 'start': 174,\n",
       " 'china': 175,\n",
       " 'fuck': 176,\n",
       " 'fall': 177,\n",
       " 'years': 178,\n",
       " 'trade': 179,\n",
       " 'yet': 180,\n",
       " 'weeks': 181,\n",
       " 'share': 182,\n",
       " 'waiting': 183,\n",
       " 'squeeze': 184,\n",
       " 'hour': 185,\n",
       " 'always': 186,\n",
       " 'sure': 187,\n",
       " 'first': 188,\n",
       " 'give': 189,\n",
       " 'shorting': 190,\n",
       " 'lot': 191,\n",
       " 'car': 192,\n",
       " 'best': 193,\n",
       " 'made': 194,\n",
       " 'options': 195,\n",
       " 'nothing': 196,\n",
       " 'pt': 197,\n",
       " 'little': 198,\n",
       " 'yall': 199,\n",
       " 'position': 200,\n",
       " 'done': 201,\n",
       " 'needs': 202,\n",
       " 'play': 203,\n",
       " 'bubble': 204,\n",
       " 'month': 205,\n",
       " 'ah': 206,\n",
       " 'since': 207,\n",
       " 'taking': 208,\n",
       " 'maybe': 209,\n",
       " 'futures': 210,\n",
       " 'load': 211,\n",
       " 'moon': 212,\n",
       " 'thanks': 213,\n",
       " 'battery': 214,\n",
       " 'months': 215,\n",
       " 'ever': 216,\n",
       " 'cheap': 217,\n",
       " 'trump': 218,\n",
       " 'pop': 219,\n",
       " 'ev': 220,\n",
       " 'bottom': 221,\n",
       " 'hours': 222,\n",
       " 'nasdaq': 223,\n",
       " 'pull': 224,\n",
       " 'thank': 225,\n",
       " 'rally': 226,\n",
       " 'lmao': 227,\n",
       " 'weekly': 228,\n",
       " 'future': 229,\n",
       " 'rip': 230,\n",
       " 'trying': 231,\n",
       " 'making': 232,\n",
       " 'everything': 233,\n",
       " 'power': 234,\n",
       " 'crazy': 235,\n",
       " 'whats': 236,\n",
       " 'free': 237,\n",
       " 'gains': 238,\n",
       " 'point': 239,\n",
       " 'stay': 240,\n",
       " 'worth': 241,\n",
       " 'fucking': 242,\n",
       " 'bye': 243,\n",
       " 'level': 244,\n",
       " 'fb': 245,\n",
       " 'weak': 246,\n",
       " 'cars': 247,\n",
       " 'weekend': 248,\n",
       " 'cover': 249,\n",
       " 'damn': 250,\n",
       " 'till': 251,\n",
       " 'told': 252,\n",
       " 'guess': 253,\n",
       " 'man': 254,\n",
       " 'remember': 255,\n",
       " 'two': 256,\n",
       " 'wants': 257,\n",
       " 'world': 258,\n",
       " 'markets': 259,\n",
       " 'dead': 260,\n",
       " 'almost': 261,\n",
       " 'something': 262,\n",
       " 'incoming': 263,\n",
       " 'post': 264,\n",
       " 'aapl': 265,\n",
       " 'feel': 266,\n",
       " 'imo': 267,\n",
       " 'added': 268,\n",
       " 'least': 269,\n",
       " 'probably': 270,\n",
       " 'fake': 271,\n",
       " 'add': 272,\n",
       " 'resistance': 273,\n",
       " 'fed': 274,\n",
       " 'nvda': 275,\n",
       " 'pm': 276,\n",
       " 'massive': 277,\n",
       " 'billion': 278,\n",
       " 'boys': 279,\n",
       " 'facebook': 280,\n",
       " 'x': 281,\n",
       " 'happen': 282,\n",
       " 'cash': 283,\n",
       " 'stupid': 284,\n",
       " 'comes': 285,\n",
       " 'biden': 286,\n",
       " 'went': 287,\n",
       " 'dollar': 288,\n",
       " 'also': 289,\n",
       " 'believe': 290,\n",
       " 'daily': 291,\n",
       " 'lose': 292,\n",
       " 'bitcoin': 293,\n",
       " 'happy': 294,\n",
       " 'beat': 295,\n",
       " 'chance': 296,\n",
       " 'away': 297,\n",
       " 'pos': 298,\n",
       " 'sorry': 299,\n",
       " 'expect': 300,\n",
       " 'sales': 301,\n",
       " 'ago': 302,\n",
       " 'minutes': 303,\n",
       " 'someone': 304,\n",
       " 'highs': 305,\n",
       " 'cap': 306,\n",
       " 'finally': 307,\n",
       " 'enough': 308,\n",
       " 'q': 309,\n",
       " 'check': 310,\n",
       " 'pay': 311,\n",
       " 'push': 312,\n",
       " 'says': 313,\n",
       " 'overvalued': 314,\n",
       " 'correction': 315,\n",
       " 'double': 316,\n",
       " 'seems': 317,\n",
       " 'ath': 318,\n",
       " 'moving': 319,\n",
       " 'ride': 320,\n",
       " 'dumb': 321,\n",
       " 'dips': 322,\n",
       " 'saying': 323,\n",
       " 'follow': 324,\n",
       " 'fast': 325,\n",
       " 'far': 326,\n",
       " 'must': 327,\n",
       " 'imagine': 328,\n",
       " 'early': 329,\n",
       " 'bag': 330,\n",
       " 'opportunity': 331,\n",
       " 'breakout': 332,\n",
       " 'left': 333,\n",
       " 'tell': 334,\n",
       " 'growth': 335,\n",
       " 'later': 336,\n",
       " 'thought': 337,\n",
       " 'luck': 338,\n",
       " 'buyers': 339,\n",
       " 'action': 340,\n",
       " 'million': 341,\n",
       " 'yes': 342,\n",
       " 'value': 343,\n",
       " 'lost': 344,\n",
       " 'th': 345,\n",
       " 'retail': 346,\n",
       " 'trend': 347,\n",
       " 'wrong': 348,\n",
       " 'burn': 349,\n",
       " 'possible': 350,\n",
       " 'investors': 351,\n",
       " 'fun': 352,\n",
       " 'ok': 353,\n",
       " 'numbers': 354,\n",
       " 'deal': 355,\n",
       " 'premarket': 356,\n",
       " 'started': 357,\n",
       " 'folks': 358,\n",
       " 'pe': 359,\n",
       " 'goo': 360,\n",
       " 'whole': 361,\n",
       " 'gets': 362,\n",
       " 'show': 363,\n",
       " 'companies': 364,\n",
       " 'bring': 365,\n",
       " 'ya': 366,\n",
       " 'else': 367,\n",
       " 'past': 368,\n",
       " 'likely': 369,\n",
       " 'miss': 370,\n",
       " 'smart': 371,\n",
       " 'mark': 372,\n",
       " 'eow': 373,\n",
       " 'thinking': 374,\n",
       " 'fill': 375,\n",
       " 'pretty': 376,\n",
       " 'wall': 377,\n",
       " 'pullback': 378,\n",
       " 'bet': 379,\n",
       " 'spy': 380,\n",
       " 'sampp': 381,\n",
       " 'tank': 382,\n",
       " 'adding': 383,\n",
       " 'test': 384,\n",
       " 'falling': 385,\n",
       " 'closing': 386,\n",
       " 'broke': 387,\n",
       " 'ass': 388,\n",
       " 'game': 389,\n",
       " 'starting': 390,\n",
       " 'head': 391,\n",
       " 'b': 392,\n",
       " 'c': 393,\n",
       " 'makes': 394,\n",
       " 'took': 395,\n",
       " 'min': 396,\n",
       " 'nvidia': 397,\n",
       " 'anything': 398,\n",
       " 'breaks': 399,\n",
       " 'theres': 400,\n",
       " 'watching': 401,\n",
       " 'continue': 402,\n",
       " 'rest': 403,\n",
       " 'seen': 404,\n",
       " 'hands': 405,\n",
       " 'iphone': 406,\n",
       " 'times': 407,\n",
       " 'less': 408,\n",
       " 'reason': 409,\n",
       " 'hey': 410,\n",
       " 'turn': 411,\n",
       " 'work': 412,\n",
       " 'hell': 413,\n",
       " 'panic': 414,\n",
       " 'small': 415,\n",
       " 'yeah': 416,\n",
       " 'cathie': 417,\n",
       " 'option': 418,\n",
       " 'line': 419,\n",
       " 'set': 420,\n",
       " 'near': 421,\n",
       " 'biggest': 422,\n",
       " 'loss': 423,\n",
       " 'quick': 424,\n",
       " 'pre': 425,\n",
       " 'ive': 426,\n",
       " 'actually': 427,\n",
       " 'sub': 428,\n",
       " 'amzn': 429,\n",
       " 'longs': 430,\n",
       " 'm': 431,\n",
       " 'loaded': 432,\n",
       " 'happened': 433,\n",
       " 'win': 434,\n",
       " 'levels': 435,\n",
       " 'range': 436,\n",
       " 'god': 437,\n",
       " 'happens': 438,\n",
       " 'breaking': 439,\n",
       " 'entry': 440,\n",
       " 'haha': 441,\n",
       " 'holders': 442,\n",
       " 'ceo': 443,\n",
       " 'trash': 444,\n",
       " 'dumping': 445,\n",
       " 'fly': 446,\n",
       " 'ahead': 447,\n",
       " 'bit': 448,\n",
       " 'greedy': 449,\n",
       " 'prices': 450,\n",
       " 'help': 451,\n",
       " 'half': 452,\n",
       " 'closed': 453,\n",
       " 'save': 454,\n",
       " 'congrats': 455,\n",
       " 'matter': 456,\n",
       " 'due': 457,\n",
       " 'running': 458,\n",
       " 'lows': 459,\n",
       " 'mean': 460,\n",
       " 'reversal': 461,\n",
       " 'swing': 462,\n",
       " 'dropping': 463,\n",
       " 'drops': 464,\n",
       " 'model': 465,\n",
       " 'super': 466,\n",
       " 'life': 467,\n",
       " 'loading': 468,\n",
       " 'covid': 469,\n",
       " 'glad': 470,\n",
       " 'stimulus': 471,\n",
       " 'major': 472,\n",
       " 'print': 473,\n",
       " 'knows': 474,\n",
       " 'gain': 475,\n",
       " 'shorted': 476,\n",
       " 'wtf': 477,\n",
       " 'cnbc': 478,\n",
       " 'report': 479,\n",
       " 'points': 480,\n",
       " 'expecting': 481,\n",
       " 'full': 482,\n",
       " 'means': 483,\n",
       " 'crypto': 484,\n",
       " 'gone': 485,\n",
       " 'pain': 486,\n",
       " 'theyre': 487,\n",
       " 'leg': 488,\n",
       " 'couple': 489,\n",
       " 'though': 490,\n",
       " 'late': 491,\n",
       " 'called': 492,\n",
       " 'rocket': 493,\n",
       " 'per': 494,\n",
       " 'try': 495,\n",
       " 'f': 496,\n",
       " 'revenue': 497,\n",
       " 'opening': 498,\n",
       " 'amazing': 499,\n",
       " 'guy': 500,\n",
       " 'heading': 501,\n",
       " 'hate': 502,\n",
       " 'side': 503,\n",
       " 'mms': 504,\n",
       " 'jump': 505,\n",
       " 'feeling': 506,\n",
       " 'talking': 507,\n",
       " 'priced': 508,\n",
       " 'wonder': 509,\n",
       " 'traders': 510,\n",
       " 'dollars': 511,\n",
       " 'tonight': 512,\n",
       " 'enjoy': 513,\n",
       " 'learn': 514,\n",
       " 'fomo': 515,\n",
       " 'order': 516,\n",
       " 'p': 517,\n",
       " 'garbage': 518,\n",
       " 'sale': 519,\n",
       " 'lots': 520,\n",
       " 'things': 521,\n",
       " 'hopefully': 522,\n",
       " 'wish': 523,\n",
       " 'whos': 524,\n",
       " 'pumping': 525,\n",
       " 'upside': 526,\n",
       " 'trillion': 527,\n",
       " 'business': 528,\n",
       " 'todays': 529,\n",
       " 'seeing': 530,\n",
       " 'rich': 531,\n",
       " 'quarter': 532,\n",
       " 'tuesday': 533,\n",
       " 'march': 534,\n",
       " 'margin': 535,\n",
       " 'expected': 536,\n",
       " 'idiots': 537,\n",
       " 'pig': 538,\n",
       " 'without': 539,\n",
       " 'rsi': 540,\n",
       " 'beautiful': 541,\n",
       " 'gotta': 542,\n",
       " 'ugly': 543,\n",
       " 'printing': 544,\n",
       " 'event': 545,\n",
       " 'flag': 546,\n",
       " 'party': 547,\n",
       " 'hits': 548,\n",
       " 'losing': 549,\n",
       " 'boom': 550,\n",
       " 'candle': 551,\n",
       " 'night': 552,\n",
       " 'teslas': 553,\n",
       " 'old': 554,\n",
       " 'forget': 555,\n",
       " 'either': 556,\n",
       " 'blood': 557,\n",
       " 'guidance': 558,\n",
       " 'valuation': 559,\n",
       " 'rug': 560,\n",
       " 'fire': 561,\n",
       " 'funny': 562,\n",
       " 'use': 563,\n",
       " 'average': 564,\n",
       " 'aint': 565,\n",
       " 'amd': 566,\n",
       " 'hes': 567,\n",
       " 'job': 568,\n",
       " 'history': 569,\n",
       " 'bezos': 570,\n",
       " 'hoping': 571,\n",
       " 'holy': 572,\n",
       " 'definitely': 573,\n",
       " 'careful': 574,\n",
       " 'playing': 575,\n",
       " 'insane': 576,\n",
       " 'pattern': 577,\n",
       " 'funds': 578,\n",
       " 'board': 579,\n",
       " 'read': 580,\n",
       " 'id': 581,\n",
       " 'losses': 582,\n",
       " 'die': 583,\n",
       " 'cat': 584,\n",
       " 'selloff': 585,\n",
       " 'anymore': 586,\n",
       " 'n': 587,\n",
       " 'joke': 588,\n",
       " 'straight': 589,\n",
       " 'rise': 590,\n",
       " 'lunch': 591,\n",
       " 'tweet': 592,\n",
       " 'plus': 593,\n",
       " 'live': 594,\n",
       " 'join': 595,\n",
       " 'positive': 596,\n",
       " 'heavy': 597,\n",
       " 'itll': 598,\n",
       " 'wanna': 599,\n",
       " 'area': 600,\n",
       " 'wake': 601,\n",
       " 'reality': 602,\n",
       " 'ask': 603,\n",
       " 'crap': 604,\n",
       " 'held': 605,\n",
       " 'keeps': 606,\n",
       " 'boy': 607,\n",
       " 'hedge': 608,\n",
       " 'starts': 609,\n",
       " 'flush': 610,\n",
       " 'manipulation': 611,\n",
       " 'positions': 612,\n",
       " 'account': 613,\n",
       " 'sense': 614,\n",
       " 'gt': 615,\n",
       " 'fear': 616,\n",
       " 'omg': 617,\n",
       " 'fucked': 618,\n",
       " 'missed': 619,\n",
       " 'perfect': 620,\n",
       " 'blow': 621,\n",
       " 'change': 622,\n",
       " 'retest': 623,\n",
       " 'st': 624,\n",
       " 'talk': 625,\n",
       " 'trust': 626,\n",
       " 'worry': 627,\n",
       " 'earning': 628,\n",
       " 'invest': 629,\n",
       " 'max': 630,\n",
       " 'potential': 631,\n",
       " 'working': 632,\n",
       " 'mm': 633,\n",
       " 'downside': 634,\n",
       " 'risk': 635,\n",
       " 'negative': 636,\n",
       " 'entire': 637,\n",
       " 'dow': 638,\n",
       " 'find': 639,\n",
       " 'welcome': 640,\n",
       " 'kill': 641,\n",
       " 'sellers': 642,\n",
       " 'listen': 643,\n",
       " 'ha': 644,\n",
       " 'nobody': 645,\n",
       " 'hot': 646,\n",
       " 'epic': 647,\n",
       " 'momentum': 648,\n",
       " 'literally': 649,\n",
       " 'room': 650,\n",
       " 'portfolio': 651,\n",
       " 'sign': 652,\n",
       " 'slow': 653,\n",
       " 'scam': 654,\n",
       " 'hype': 655,\n",
       " 'beast': 656,\n",
       " 'easily': 657,\n",
       " 'street': 658,\n",
       " 'virus': 659,\n",
       " 'charts': 660,\n",
       " 't': 661,\n",
       " 'happening': 662,\n",
       " 'premium': 663,\n",
       " 'surprised': 664,\n",
       " 'rate': 665,\n",
       " 'jan': 666,\n",
       " 'poor': 667,\n",
       " 'inflation': 668,\n",
       " 'interesting': 669,\n",
       " 'powell': 670,\n",
       " 'cramer': 671,\n",
       " 'mins': 672,\n",
       " 'touch': 673,\n",
       " 'overpriced': 674,\n",
       " 'bigger': 675,\n",
       " 'cut': 676,\n",
       " 'zero': 677,\n",
       " 'second': 678,\n",
       " 'number': 679,\n",
       " 'opens': 680,\n",
       " 'bitch': 681,\n",
       " 'instead': 682,\n",
       " 'worse': 683,\n",
       " 'worst': 684,\n",
       " 'alert': 685,\n",
       " 'place': 686,\n",
       " 'deep': 687,\n",
       " 'understand': 688,\n",
       " 'true': 689,\n",
       " 'fraud': 690,\n",
       " 'cmon': 691,\n",
       " 'buys': 692,\n",
       " 'analyst': 693,\n",
       " 'electric': 694,\n",
       " 'case': 695,\n",
       " 'scared': 696,\n",
       " 'mind': 697,\n",
       " 'current': 698,\n",
       " 'burry': 699,\n",
       " 'economy': 700,\n",
       " 'continues': 701,\n",
       " 'investment': 702,\n",
       " 'overnight': 703,\n",
       " 'thursday': 704,\n",
       " 'covering': 705,\n",
       " 'idea': 706,\n",
       " 'elons': 707,\n",
       " 'catch': 708,\n",
       " 'cause': 709,\n",
       " 'forward': 710,\n",
       " 'within': 711,\n",
       " 'bs': 712,\n",
       " 'safe': 713,\n",
       " 'minute': 714,\n",
       " 'ai': 715,\n",
       " 'hahaha': 716,\n",
       " 'paid': 717,\n",
       " 'twitter': 718,\n",
       " 'moves': 719,\n",
       " 'moment': 720,\n",
       " 'oil': 721,\n",
       " 'd': 722,\n",
       " 'data': 723,\n",
       " 'bucks': 724,\n",
       " 'headed': 725,\n",
       " 'chinese': 726,\n",
       " 'delivery': 727,\n",
       " 'calling': 728,\n",
       " 'vs': 729,\n",
       " 'house': 730,\n",
       " 'dropped': 731,\n",
       " 'oversold': 732,\n",
       " 'nio': 733,\n",
       " 'sells': 734,\n",
       " 'beginning': 735,\n",
       " 'care': 736,\n",
       " 'fools': 737,\n",
       " 'demand': 738,\n",
       " 'space': 739,\n",
       " 'flat': 740,\n",
       " 'flow': 741,\n",
       " 'home': 742,\n",
       " 'saw': 743,\n",
       " 'strike': 744,\n",
       " 'consolidation': 745,\n",
       " 'overbought': 746,\n",
       " 'ur': 747,\n",
       " 'zuck': 748,\n",
       " 'solid': 749,\n",
       " 'piece': 750,\n",
       " 'eoy': 751,\n",
       " 'kids': 752,\n",
       " 'spike': 753,\n",
       " 'robinhood': 754,\n",
       " 'face': 755,\n",
       " 'war': 756,\n",
       " 'become': 757,\n",
       " 'media': 758,\n",
       " 'expiring': 759,\n",
       " 'eat': 760,\n",
       " 'sec': 761,\n",
       " 'record': 762,\n",
       " 'penny': 763,\n",
       " 'stockorbit': 764,\n",
       " 'chip': 765,\n",
       " 'crashing': 766,\n",
       " 'gl': 767,\n",
       " 'forever': 768,\n",
       " 'tax': 769,\n",
       " 'giving': 770,\n",
       " 'name': 771,\n",
       " 'question': 772,\n",
       " 'cross': 773,\n",
       " 'longer': 774,\n",
       " 'part': 775,\n",
       " 'bank': 776,\n",
       " 'movement': 777,\n",
       " 'christmas': 778,\n",
       " 'fight': 779,\n",
       " 'fade': 780,\n",
       " 'excited': 781,\n",
       " 'hmm': 782,\n",
       " 'bleed': 783,\n",
       " 'sad': 784,\n",
       " 'fair': 785,\n",
       " 'filled': 786,\n",
       " 'simulated': 787,\n",
       " 'send': 788,\n",
       " 'coronavirus': 789,\n",
       " 'sleep': 790,\n",
       " 'absolutely': 791,\n",
       " 'cheaper': 792,\n",
       " 'intraday': 793,\n",
       " 'upgrade': 794,\n",
       " 'bell': 795,\n",
       " 'tim': 796,\n",
       " 'based': 797,\n",
       " 'knew': 798,\n",
       " 'turd': 799,\n",
       " 'idiot': 800,\n",
       " 'ppl': 801,\n",
       " 'production': 802,\n",
       " 'analysts': 803,\n",
       " 'death': 804,\n",
       " 'expensive': 805,\n",
       " 'doubt': 806,\n",
       " 'repeat': 807,\n",
       " 'upgrades': 808,\n",
       " 'afternoon': 809,\n",
       " 'af': 810,\n",
       " 'metaverse': 811,\n",
       " 'healthy': 812,\n",
       " 'telling': 813,\n",
       " 'cool': 814,\n",
       " 'r': 815,\n",
       " 'phone': 816,\n",
       " 'lotto': 817,\n",
       " 'realize': 818,\n",
       " 'downtrend': 819,\n",
       " 'signal': 820,\n",
       " 'hear': 821,\n",
       " 'em': 822,\n",
       " 'global': 823,\n",
       " 'plan': 824,\n",
       " 'meta': 825,\n",
       " 'feels': 826,\n",
       " 'july': 827,\n",
       " 'broken': 828,\n",
       " 'interest': 829,\n",
       " 'wave': 830,\n",
       " 'america': 831,\n",
       " 'roll': 832,\n",
       " 'announcement': 833,\n",
       " 'sp': 834,\n",
       " 'train': 835,\n",
       " 'feb': 836,\n",
       " 'total': 837,\n",
       " 'announce': 838,\n",
       " 'competition': 839,\n",
       " 'gift': 840,\n",
       " 'pick': 841,\n",
       " 'percent': 842,\n",
       " 'single': 843,\n",
       " 'forming': 844,\n",
       " 'june': 845,\n",
       " 'discount': 846,\n",
       " 'came': 847,\n",
       " 'control': 848,\n",
       " 'tanking': 849,\n",
       " 'bunch': 850,\n",
       " 'used': 851,\n",
       " 'wk': 852,\n",
       " 'others': 853,\n",
       " 'killing': 854,\n",
       " 'reach': 855,\n",
       " 'smh': 856,\n",
       " 'vwap': 857,\n",
       " 'orders': 858,\n",
       " 'holds': 859,\n",
       " 'sector': 860,\n",
       " 'patience': 861,\n",
       " 'futes': 862,\n",
       " 'along': 863,\n",
       " 'closes': 864,\n",
       " 'earlier': 865,\n",
       " 'algos': 866,\n",
       " 'recovery': 867,\n",
       " 'btc': 868,\n",
       " 'clear': 869,\n",
       " 'large': 870,\n",
       " 'trades': 871,\n",
       " 'september': 872,\n",
       " 'takes': 873,\n",
       " 'heard': 874,\n",
       " 'offering': 875,\n",
       " 'able': 876,\n",
       " 'following': 877,\n",
       " 'covered': 878,\n",
       " 'rising': 879,\n",
       " 'fine': 880,\n",
       " 'leave': 881,\n",
       " 'mode': 882,\n",
       " 'wednesday': 883,\n",
       " 'using': 884,\n",
       " 'chips': 885,\n",
       " 'april': 886,\n",
       " 'factory': 887,\n",
       " 'shut': 888,\n",
       " 'seriously': 889,\n",
       " 'three': 890,\n",
       " 'w': 891,\n",
       " 'worthless': 892,\n",
       " 'handle': 893,\n",
       " 'hitting': 894,\n",
       " 'driving': 895,\n",
       " 'limit': 896,\n",
       " 'release': 897,\n",
       " 'setting': 898,\n",
       " 'paying': 899,\n",
       " 'awesome': 900,\n",
       " 'reverse': 901,\n",
       " 'undervalued': 902,\n",
       " 'dumped': 903,\n",
       " 'black': 904,\n",
       " 'g': 905,\n",
       " 'etc': 906,\n",
       " 'slowly': 907,\n",
       " 'suck': 908,\n",
       " 'ones': 909,\n",
       " 'showing': 910,\n",
       " 'zone': 911,\n",
       " 'raise': 912,\n",
       " 'increase': 913,\n",
       " 'imminent': 914,\n",
       " 'y': 915,\n",
       " 'kind': 916,\n",
       " 'smell': 917,\n",
       " 'social': 918,\n",
       " 'heres': 919,\n",
       " 'energy': 920,\n",
       " 'president': 921,\n",
       " 'strength': 922,\n",
       " 'crushed': 923,\n",
       " 'worried': 924,\n",
       " 'clowns': 925,\n",
       " 'supply': 926,\n",
       " 'cult': 927,\n",
       " 'recover': 928,\n",
       " 'mars': 929,\n",
       " 'soo': 930,\n",
       " 'ripping': 931,\n",
       " 'trapped': 932,\n",
       " 'google': 933,\n",
       " 'pass': 934,\n",
       " 'ship': 935,\n",
       " 'drive': 936,\n",
       " 'plays': 937,\n",
       " 'launch': 938,\n",
       " 'channel': 939,\n",
       " 'unless': 940,\n",
       " 'lt': 941,\n",
       " 'bill': 942,\n",
       " 'hand': 943,\n",
       " 'doge': 944,\n",
       " 'ridiculous': 945,\n",
       " 'king': 946,\n",
       " 'joe': 947,\n",
       " 'spread': 948,\n",
       " 'mid': 949,\n",
       " 'recession': 950,\n",
       " 'flying': 951,\n",
       " 'warned': 952,\n",
       " 'confirmed': 953,\n",
       " 'corona': 954,\n",
       " 'wheres': 955,\n",
       " 'bags': 956,\n",
       " 'story': 957,\n",
       " 'wood': 958,\n",
       " 'tmrw': 959,\n",
       " 'balls': 960,\n",
       " 'monster': 961,\n",
       " 'rn': 962,\n",
       " 'tight': 963,\n",
       " 'products': 964,\n",
       " 'v': 965,\n",
       " 'begin': 966,\n",
       " 'january': 967,\n",
       " 'contracts': 968,\n",
       " 'billions': 969,\n",
       " 'video': 970,\n",
       " 'shows': 971,\n",
       " 'especially': 972,\n",
       " 'trending': 973,\n",
       " 'exit': 974,\n",
       " 'truck': 975,\n",
       " 'beyond': 976,\n",
       " 'everybody': 977,\n",
       " 'behind': 978,\n",
       " 'towards': 979,\n",
       " 'rates': 980,\n",
       " 'targets': 981,\n",
       " 'knife': 982,\n",
       " 'course': 983,\n",
       " 'wanted': 984,\n",
       " 'falls': 985,\n",
       " 'problem': 986,\n",
       " 'investing': 987,\n",
       " 'hurt': 988,\n",
       " 'jobs': 989,\n",
       " 'sideways': 990,\n",
       " 'announced': 991,\n",
       " 'friends': 992,\n",
       " 'valued': 993,\n",
       " 'crush': 994,\n",
       " 'fact': 995,\n",
       " 'posts': 996,\n",
       " 'normal': 997,\n",
       " 'ratio': 998,\n",
       " 'lmfao': 999,\n",
       " 'dec': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ce55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
