{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0968a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import string\n",
    "from transformers import (BertTokenizer, BertForMaskedLM, XLNetTokenizer, XLNetModel, \n",
    "                          AutoModelWithLMHead, AutoTokenizer, top_k_top_p_filtering, logging)\n",
    "from transformers import (RobertaForSequenceClassification, RobertaTokenizer, \n",
    "    BertForSequenceClassification, BertTokenizer, \n",
    "    AutoModelForSequenceClassification, AutoTokenizer, AdamW)\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a089f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_words_to_be_predicted = globals()\n",
    "select_model = globals()\n",
    "enter_input_text = globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afcb9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/large_datafiles/all_tweets_2015_2022.csv').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725e87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_config(**kwargs):\n",
    "    \n",
    "    for key, value in kwargs.items():\n",
    "        print(\"{0} = {1}\".format(key, value))\n",
    "\n",
    "    no_words_to_be_predicted = list(kwargs.values())[0] # integer values\n",
    "    select_model = list(kwargs.values())[1] # possible values = 'bert' or 'gpt' or 'xlnet'\n",
    "    enter_input_text = list(kwargs.values())[2] #only string\n",
    "\n",
    "    return no_words_to_be_predicted, select_model, enter_input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf695ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('./data/model')\n",
    "model = RobertaForSequenceClassification.from_pretrained('./data/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20beb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    try:\n",
    "        if model_name.lower() == \"bert\":\n",
    "            bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "            bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()\n",
    "            return bert_tokenizer,bert_model\n",
    "        elif model_name.lower() == \"gpt\":\n",
    "            gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "            gpt_model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "            return gpt_tokenizer,gpt_model\n",
    "        else:\n",
    "            xlnet_tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "            xlnet_model = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\")\n",
    "            return xlnet_tokenizer, xlnet_model\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056fed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_bert(tokenizer, text_sentence, add_special_tokens=True):\n",
    "    text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
    "    # if <mask> is the last token, append a \".\" so that models dont predict punctuation.\n",
    "    if tokenizer.mask_token == text_sentence.split()[-1]:\n",
    "        text_sentence += ' .'\n",
    "        input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
    "        mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
    "    return input_ids, mask_idx\n",
    "  \n",
    "# bert decode\n",
    "def decode_bert(tokenizer, pred_idx, top_clean):\n",
    "    ignore_tokens = string.punctuation + '[PAD]'\n",
    "    tokens = []\n",
    "    for w in pred_idx:\n",
    "        token = ''.join(tokenizer.decode(w).split())\n",
    "        if token not in ignore_tokens:\n",
    "            tokens.append(token.replace('##', ''))\n",
    "    return '\\n'.join(tokens[:top_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d819537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "370404f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_end_of_sentence(input_text, model_name):\n",
    "    try:\n",
    "        if model_name.lower() == \"bert\":\n",
    "            input_text += ' <mask>'\n",
    "            print(input_text)\n",
    "            res = get_all_predictions(input_text, model_name, top_clean=int(no_words_to_be_predicted)) \n",
    "            return res\n",
    "        elif model_name.lower() == \"gpt\":\n",
    "            print(input_text)\n",
    "            res = get_all_predictions(input_text, model_name, top_clean=int(no_words_to_be_predicted)) \n",
    "            return res\n",
    "        else:\n",
    "            print(input_text)\n",
    "            res = get_all_predictions(input_text, model_name, top_clean=int(no_words_to_be_predicted))\n",
    "            return res\n",
    "\n",
    "    except Exception as error:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05314305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi <mask>\n"
     ]
    }
   ],
   "source": [
    "get_prediction_end_of_sentence('hi', 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6fcec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Word Prediction with Pytorch using BERT, GPT, and XLNet\n",
      "no_words_to_be_predicted = 5\n",
      "select_model = bert\n",
      "enter_input_text = why are\n",
      "why are <mask>\n",
      "result is: None\n",
      "Some problem occured\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Next Word Prediction with Pytorch using BERT, GPT, and XLNet\")\n",
    "    no_words_to_be_predicted, select_model, enter_input_text = set_model_config(\n",
    "        no_words_to_be_predicted=5, select_model = \"bert\", enter_input_text = \"why are\")\n",
    "    if select_model.lower() == \"bert\":\n",
    "        bert_tokenizer, bert_model  = load_model(select_model)\n",
    "        res = get_prediction_end_of_sentence(enter_input_text, select_model)\n",
    "        print(\"result is: {}\" .format(res))\n",
    "        answer_bert = []\n",
    "        print(res['bert'].split(\"\\n\"))\n",
    "        for i in res['bert'].split(\"\\n\"):\n",
    "            answer_bert.append(i)\n",
    "            answer_as_string_bert = \"    \".join(answer_bert)\n",
    "            print(\"output answer is: {}\" .format(answer_as_string_bert))\n",
    "except Exception as e:\n",
    "    print('Some problem occured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c1eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
