{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0968a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate (_ssl.c:1131)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate (_ssl.c:1131)>\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate (_ssl.c:1131)>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate (_ssl.c:1131)>\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "# numericalization\n",
    "from collections import Counter\n",
    "\n",
    "# preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # will give an altered version later cuz the default isn't great\n",
    "from string import punctuation\n",
    "# from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# neural nets\n",
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras import Sequential, Input, optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "title_fontsize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d628f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/large_datafiles/all_stock_score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860c11c",
   "metadata": {},
   "source": [
    "### Cleaning up the Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8742162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/preprocessing/balanced_tokenized_cleaned_stocktwits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445c43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./data/preprocessing/padded_X.csv')\n",
    "y = pd.read_csv('./data/preprocessing/padded_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf16a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743052, 253288)\n",
      "(743052, 253288)\n",
      "(185764, 253288)\n",
      "(185764, 253288)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[\"body\"], df[\"sentiment\"], test_size = 0.2, random_state = 42)\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)\n",
    "\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
    "print(x_train_counts.shape)\n",
    "print(x_train_tfidf.shape)\n",
    "\n",
    "\n",
    "x_test_counts = count_vect.transform(x_test)\n",
    "x_test_tfidf = transformer.transform(x_test_counts)\n",
    "print(x_test_counts.shape)\n",
    "print(x_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(x_train_tfidf,y_train)\n",
    "predictions = model.predict(x_test_tfidf)\n",
    "\n",
    "#Confusion Matrix \n",
    "confusion_matrix(y_test,predictions)\n",
    "\n",
    "#f1-score\n",
    "f1_score(y_test,predictions)\n",
    "\n",
    "#Accuracy_score\n",
    "accuracy_score(y_test,predictions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a863f9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'going': 106020,\n",
       " 'right': 212646,\n",
       " 'throughsupport': 257109,\n",
       " 'as': 16952,\n",
       " 'if': 124216,\n",
       " 'it': 133188,\n",
       " 'isnt': 132522,\n",
       " 'even': 84242,\n",
       " 'thereis': 253322,\n",
       " 'the': 250610,\n",
       " 'superior': 242303,\n",
       " 'growth': 109616,\n",
       " 'trade': 266997,\n",
       " 'nobody': 169637,\n",
       " 'gonna': 106563,\n",
       " 'buy': 43422,\n",
       " 'expensive': 86687,\n",
       " 'ass': 17549,\n",
       " 'iphones': 131381,\n",
       " 'when': 286156,\n",
       " 'they': 254407,\n",
       " 'aint': 6842,\n",
       " 'got': 107518,\n",
       " 'any': 13659,\n",
       " 'money': 159767,\n",
       " 'lol': 145943,\n",
       " 'no': 169603,\n",
       " 'stimulus': 238028,\n",
       " 'dumb': 77088,\n",
       " 'apple': 14430,\n",
       " 'cult': 63593,\n",
       " 'buyers': 43766,\n",
       " 'lmao': 145215,\n",
       " 'dumbest': 77132,\n",
       " 'people': 188522,\n",
       " 'on': 176991,\n",
       " 'planet': 190660,\n",
       " 'robinhood': 213892,\n",
       " 'peeps': 188178,\n",
       " 'be': 26095,\n",
       " 'severely': 223700,\n",
       " 'disappointed': 71144,\n",
       " 'with': 288423,\n",
       " 'this': 255262,\n",
       " 'turd': 270651,\n",
       " 'today': 260196,\n",
       " 'always': 9084,\n",
       " 'dump': 77266,\n",
       " 'why': 287297,\n",
       " 'is': 131714,\n",
       " 'not': 170421,\n",
       " 'anywhere': 14023,\n",
       " 'pathetic': 187236,\n",
       " 'increase': 126753,\n",
       " 'of': 173833,\n",
       " 'iphone': 131147,\n",
       " 'sales': 216917,\n",
       " 'compared': 57571,\n",
       " 'to': 259395,\n",
       " 'that': 249501,\n",
       " 'during': 77825,\n",
       " 'pandemic': 185923,\n",
       " 'thats': 250247,\n",
       " 'headline': 114622,\n",
       " 'will': 287652,\n",
       " 'end': 81256,\n",
       " 'upcents': 274653,\n",
       " 'profit': 197412,\n",
       " 'in': 125841,\n",
       " 'dry': 76835,\n",
       " 'paint': 185753,\n",
       " 'stock': 238224,\n",
       " 'pump': 199460,\n",
       " 'uh': 271740,\n",
       " 'oh': 176166,\n",
       " 'down': 73949,\n",
       " 'she': 224758,\n",
       " 'goes': 105698,\n",
       " 'belowtmrw': 30287,\n",
       " 'just': 136980,\n",
       " 'gotmonths': 107704,\n",
       " 'free': 97814,\n",
       " 'from': 98800,\n",
       " 'months': 160623,\n",
       " 'until': 274031,\n",
       " 'summer': 242069,\n",
       " 'wont': 290164,\n",
       " 'run': 215564,\n",
       " 'week': 283473,\n",
       " 'before': 28422,\n",
       " 'earnings': 78404,\n",
       " 'toward': 266451,\n",
       " 'january': 135101,\n",
       " 'boring': 35676,\n",
       " 'must': 164191,\n",
       " 'go': 105324,\n",
       " 'lowerafter': 148950,\n",
       " 'big': 32332,\n",
       " 'guyscame': 110874,\n",
       " 'topalternatives': 264532,\n",
       " 'peloton': 188310,\n",
       " 'bike': 32737,\n",
       " 'andechelon': 11388,\n",
       " 'exs': 87215,\n",
       " 'bowflex': 37047,\n",
       " 'velocore': 278286,\n",
       " 'nordictrack': 170232,\n",
       " 'si': 228269,\n",
       " 'schwinn': 219312,\n",
       " 'ic': 123713,\n",
       " 'pooboo': 192537,\n",
       " 'commercial': 56888,\n",
       " 'stationary': 237227,\n",
       " 'tradedfor': 267058,\n",
       " 'did': 69645,\n",
       " 'my': 164373,\n",
       " 'portfolio': 193061,\n",
       " 'wonders': 290125,\n",
       " 'below': 29562,\n",
       " 'fair': 88368,\n",
       " 'value': 277768,\n",
       " 'because': 27935,\n",
       " 'ofandsport': 173968,\n",
       " 'take': 244224,\n",
       " 'market': 152582,\n",
       " 'bear': 26195,\n",
       " 'mode': 158653,\n",
       " 'and': 11021,\n",
       " 'probably': 196873,\n",
       " 'all': 7645,\n",
       " 'weeklets': 284081,\n",
       " 'have': 113996,\n",
       " 'some': 232434,\n",
       " 'thr': 256817,\n",
       " 'mood': 160816,\n",
       " 'beer': 28345,\n",
       " 'for': 94860,\n",
       " 'responsible': 210713,\n",
       " 'bloomberg': 34321,\n",
       " 'part': 186433,\n",
       " 'problemwhy': 197056,\n",
       " 'looks': 147636,\n",
       " 'like': 143168,\n",
       " 'diamond': 69534,\n",
       " 'top': 264522,\n",
       " 'dead': 66585,\n",
       " 'piece': 189890,\n",
       " 'shit': 225269,\n",
       " 'im': 124967,\n",
       " 'gay': 103177,\n",
       " 'proud': 198405,\n",
       " 'every': 84835,\n",
       " 'day': 65289,\n",
       " 'bloody': 34304,\n",
       " 'red': 207740,\n",
       " 'more': 161177,\n",
       " 'selling': 221841,\n",
       " 'tomorrow': 262835,\n",
       " 'into': 129851,\n",
       " 'rest': 210733,\n",
       " 'support': 242441,\n",
       " 'between': 31420,\n",
       " 'volume': 279392,\n",
       " 'android': 12030,\n",
       " 'puts': 200467,\n",
       " 'at': 18054,\n",
       " 'lasttop': 140137,\n",
       " 'oi': 176336,\n",
       " 'tells': 246674,\n",
       " 'me': 154497,\n",
       " 'call': 46160,\n",
       " 'sale': 216841,\n",
       " 'premium': 195337,\n",
       " 'collection': 55748,\n",
       " 'coming': 56291,\n",
       " 'power': 194425,\n",
       " 'hour': 121895,\n",
       " 'breakdown': 37930,\n",
       " 'pre': 194719,\n",
       " 'vieo': 278772,\n",
       " 'puke': 199172,\n",
       " 'already': 8637,\n",
       " 'put': 200304,\n",
       " 'spread': 235527,\n",
       " 'fro': 98786,\n",
       " 'last': 139855,\n",
       " 'needs': 166698,\n",
       " 'get': 103751,\n",
       " 'moving': 162993,\n",
       " 'later': 140308,\n",
       " 'back': 23421,\n",
       " 'slacker': 229897,\n",
       " 'terrible': 247097,\n",
       " 'hold': 119803,\n",
       " 'lastmonths': 140026,\n",
       " 'waste': 281798,\n",
       " 'time': 258236,\n",
       " 'missed': 157993,\n",
       " 'opportunity': 180431,\n",
       " 'other': 181600,\n",
       " 'gems': 103403,\n",
       " 'about': 609,\n",
       " 'fallon': 88791,\n",
       " 'failed': 88220,\n",
       " 'weakness': 283018,\n",
       " 'expect': 86259,\n",
       " 'drop': 76054,\n",
       " 'sold': 231901,\n",
       " 'short': 225977,\n",
       " 'such': 241620,\n",
       " 'opening': 179857,\n",
       " 'position': 193244,\n",
       " 'tightly': 257768,\n",
       " 'coiled': 55477,\n",
       " 'pile': 190123,\n",
       " 'dog': 72533,\n",
       " 'crap': 61553,\n",
       " 'cant': 47711,\n",
       " 'weeksgain': 284509,\n",
       " 'so': 231457,\n",
       " 'close': 53819,\n",
       " 'yet': 295212,\n",
       " 'we': 282907,\n",
       " 'dont': 73334,\n",
       " 'see': 220243,\n",
       " 'bears': 26651,\n",
       " 'please': 191334,\n",
       " 'add': 3173,\n",
       " 'yo': 295655,\n",
       " 'shirts': 225260,\n",
       " 'plz': 191774,\n",
       " 'do': 72225,\n",
       " 'immediately': 125212,\n",
       " 'need': 166504,\n",
       " 'thatto': 250447,\n",
       " 'break': 37798,\n",
       " 'definitely': 67924,\n",
       " 'keeping': 137639,\n",
       " 'up': 274405,\n",
       " 'joness': 136158,\n",
       " 'here': 115702,\n",
       " 'were': 285443,\n",
       " 'discount': 71321,\n",
       " 'what': 285762,\n",
       " 'can': 47252,\n",
       " 'say': 218029,\n",
       " 'anyone': 13824,\n",
       " 'has': 113578,\n",
       " 'problems': 197023,\n",
       " 'thinkorswim': 255075,\n",
       " 'todayits': 260716,\n",
       " 'lagging': 139543,\n",
       " 'days': 65926,\n",
       " 'keep': 137605,\n",
       " 'saying': 218142,\n",
       " 'out': 182035,\n",
       " 'juice': 136359,\n",
       " 'atthen': 21156,\n",
       " 'sell': 221548,\n",
       " 'againit': 5290,\n",
       " 'didnt': 69741,\n",
       " 'breakeod': 37969,\n",
       " 'once': 177349,\n",
       " 'hitsim': 119005,\n",
       " 'looking': 147535,\n",
       " 'by': 45104,\n",
       " 'daywithin': 66401,\n",
       " 'two': 271316,\n",
       " 'pos': 193171,\n",
       " 'putson': 200869,\n",
       " 'spike': 234740,\n",
       " 'may': 153972,\n",
       " 'testagain': 248143,\n",
       " 'another': 12820,\n",
       " 'burn': 42376,\n",
       " 'your': 296233,\n",
       " 'options': 180685,\n",
       " 'theta': 254073,\n",
       " 'freakin': 97777,\n",
       " 'snail': 231190,\n",
       " 'tired': 259031,\n",
       " 'non': 169895,\n",
       " 'movement': 162728,\n",
       " 'since': 228987,\n",
       " 'split': 234943,\n",
       " 'levermann': 142611,\n",
       " 'us': 276658,\n",
       " 'megacap': 155247,\n",
       " 'wkunh': 289864,\n",
       " 'factory': 87976,\n",
       " 'vandalized': 278003,\n",
       " 'workers': 290562,\n",
       " 'india': 127103,\n",
       " 'discontent': 71298,\n",
       " 'over': 183140,\n",
       " 'wages': 280241,\n",
       " 'working': 290597,\n",
       " 'hours': 122076,\n",
       " 'article': 16846,\n",
       " 'whats': 285980,\n",
       " 'thoughts': 256709,\n",
       " 'pop': 192665,\n",
       " 'early': 78188,\n",
       " 'am': 9158,\n",
       " 'reject': 208778,\n",
       " 'off': 174408,\n",
       " 'theemas': 251344,\n",
       " 'then': 252440,\n",
       " 'real': 206329,\n",
       " 'begins': 28874,\n",
       " 'weekwill': 284802,\n",
       " 'tumble': 270570,\n",
       " 'fearful': 90241,\n",
       " 'others': 181665,\n",
       " 'are': 15522,\n",
       " 'greedywarren': 108739,\n",
       " 'buffett': 40727,\n",
       " 'weeks': 284448,\n",
       " 'theme': 252124,\n",
       " 'goneby': 106450,\n",
       " 'thursday': 257387,\n",
       " 'global': 105077,\n",
       " 'nutshell': 172800,\n",
       " 'nowto': 172161,\n",
       " 'moon': 160837,\n",
       " 'next': 168125,\n",
       " 'tech': 246182,\n",
       " 'you': 295812,\n",
       " 'know': 138718,\n",
       " 'bad': 23953,\n",
       " 'month': 160443,\n",
       " 'bulls': 41412,\n",
       " 'true': 269382,\n",
       " 'feel': 90750,\n",
       " 'bullish': 41043,\n",
       " 'drops': 76533,\n",
       " 'weak': 282912,\n",
       " 'imo': 125343,\n",
       " 'thanmonths': 249218,\n",
       " 'cannot': 47648,\n",
       " 'amove': 10148,\n",
       " 'qualcomm': 201665,\n",
       " 'but': 42917,\n",
       " 'also': 8915,\n",
       " 'usually': 277299,\n",
       " 'these': 253611,\n",
       " 'thethe': 254128,\n",
       " 'obese': 173272,\n",
       " 'greasy': 108432,\n",
       " 'swine': 243597,\n",
       " 'desperately': 69056,\n",
       " 'calling': 46385,\n",
       " 'acut': 3101,\n",
       " 'absolutely': 2033,\n",
       " 'delusional': 68395,\n",
       " 'goodmarket': 106887,\n",
       " 'cookedcant': 59541,\n",
       " 'higheronly': 117364,\n",
       " 'way': 282598,\n",
       " 'now': 171229,\n",
       " 'getting': 104062,\n",
       " 'wrecked': 292206,\n",
       " 'bigly': 32553,\n",
       " 'fucking': 100416,\n",
       " 'garbage': 102885,\n",
       " 'hanging': 112724,\n",
       " 'thread': 256829,\n",
       " 'cliff': 53583,\n",
       " 'edge': 79662,\n",
       " 'epic': 82761,\n",
       " 'proportions': 198254,\n",
       " 'been': 28245,\n",
       " 'sleeping': 230155,\n",
       " 'than': 248728,\n",
       " 'three': 256876,\n",
       " 'santa': 217683,\n",
       " 'clause': 53350,\n",
       " 'rallynope': 204940,\n",
       " 'party': 186602,\n",
       " 'starting': 237000,\n",
       " 'december': 67259,\n",
       " 'fridays': 98384,\n",
       " 'almost': 8202,\n",
       " 'redsometimes': 208145,\n",
       " 'its': 133947,\n",
       " 'simple': 228897,\n",
       " 'bank': 24953,\n",
       " 'remember': 209326,\n",
       " 'bought': 36238,\n",
       " 'dip': 70326,\n",
       " 'was': 281416,\n",
       " 'actually': 3048,\n",
       " 'happening': 112919,\n",
       " 'ticker': 257546,\n",
       " 'great': 108433,\n",
       " 'company': 57190,\n",
       " 'wayy': 282850,\n",
       " 'overpriced': 184248,\n",
       " 'ouch': 181812,\n",
       " 'fucckk': 100227,\n",
       " 'too': 264056,\n",
       " 'could': 60462,\n",
       " 'easily': 79027,\n",
       " 'made': 150463,\n",
       " 'ready': 206212,\n",
       " 'toor': 264338,\n",
       " 'look': 147473,\n",
       " 'pt': 198711,\n",
       " 'trapped': 268072,\n",
       " 'many': 152083,\n",
       " 'yesterday': 294829,\n",
       " 'doing': 72726,\n",
       " 'exact': 85562,\n",
       " 'same': 217176,\n",
       " 'give': 104782,\n",
       " 'gains': 102153,\n",
       " 'seeing': 220610,\n",
       " 'cobbled': 55296,\n",
       " 'trash': 268234,\n",
       " 'ipo': 131500,\n",
       " 'making': 151338,\n",
       " 'killing': 138171,\n",
       " 'want': 280800,\n",
       " 'invest': 130433,\n",
       " 'toat': 259760,\n",
       " 'point': 192085,\n",
       " 'onput': 178933,\n",
       " 'assets': 17645,\n",
       " 'forever': 95601,\n",
       " 'fed': 90615,\n",
       " 'bail': 24545,\n",
       " 'america': 9836,\n",
       " 'collapses': 55688,\n",
       " 'yupme': 297005,\n",
       " 'neither': 166986,\n",
       " 'roll': 214448,\n",
       " 'overstockmarkettrading': 184614,\n",
       " 'investingswingtrading': 130561,\n",
       " 'optionstrading': 180858,\n",
       " 'charting': 50996,\n",
       " 'cycleanalysis': 64222,\n",
       " 'our': 181912,\n",
       " 'come': 55921,\n",
       " 'hibernation': 117041,\n",
       " 'rise': 213301,\n",
       " 'sharpen': 224669,\n",
       " 'those': 256304,\n",
       " 'claws': 53358,\n",
       " 'battle': 25844,\n",
       " 'mcconnell': 154385,\n",
       " 'rejects': 208904,\n",
       " 'bipartisan': 33059,\n",
       " 'covid': 61066,\n",
       " 'relief': 209163,\n",
       " 'plan': 190629,\n",
       " 'while': 286717,\n",
       " 'house': 122313,\n",
       " 'adjourns': 3753,\n",
       " 'weekno': 284307,\n",
       " 'double': 73721,\n",
       " 'signal': 228578,\n",
       " 'alertmore': 7320,\n",
       " 'insights': 129021,\n",
       " 'utmmediumautopost': 277413,\n",
       " 'whos': 287241,\n",
       " 'christmas': 52778,\n",
       " 'crash': 61673,\n",
       " 'retestlows': 211235,\n",
       " 'again': 5022,\n",
       " 'priced': 195919,\n",
       " 'yall': 293458,\n",
       " 'learnthere': 141114,\n",
       " 'stimulusbeen': 238034,\n",
       " 'pulling': 199375,\n",
       " 'chains': 50278,\n",
       " 'formonths': 96404,\n",
       " 'option': 180630,\n",
       " 'price': 195856,\n",
       " 'watch': 281917,\n",
       " 'super': 242240,\n",
       " 'incoming': 126490,\n",
       " 'bull': 40911,\n",
       " 'trap': 267895,\n",
       " 'one': 177599,\n",
       " 'retest': 211127,\n",
       " 'yesterdays': 295056,\n",
       " 'lows': 149328,\n",
       " 'war': 281142,\n",
       " 'aapllike': 210,\n",
       " 'saidaint': 216489,\n",
       " 'convinced': 59494,\n",
       " 'psst': 198578,\n",
       " 'cue': 63559,\n",
       " 'leg': 141715,\n",
       " 'able': 531,\n",
       " 'there': 253201,\n",
       " 'thesis': 253928,\n",
       " 'intel': 129454,\n",
       " 'seems': 220819,\n",
       " 'theyre': 254472,\n",
       " 'sides': 228425,\n",
       " 'byand': 45137,\n",
       " 'pucker': 199137,\n",
       " 'butt': 43219,\n",
       " 'cheeks': 51775,\n",
       " 'kids': 138017,\n",
       " 'lube': 149770,\n",
       " 'readymarket': 206279,\n",
       " 'movers': 162828,\n",
       " 'trapgoing': 267987,\n",
       " 'deep': 67727,\n",
       " 'todaystill': 261188,\n",
       " 'stimulusmonths': 238061,\n",
       " 'counting': 60573,\n",
       " 'empty': 81184,\n",
       " 'promiseseconomy': 198112,\n",
       " 'total': 265539,\n",
       " 'meltdown': 155446,\n",
       " 'how': 122409,\n",
       " 'notyet': 171032,\n",
       " 'haha': 111445,\n",
       " 'giftnews': 104403,\n",
       " 'fully': 100879,\n",
       " 'accounted': 2378,\n",
       " 'bleed': 33844,\n",
       " 'recover': 207539,\n",
       " 'toyour': 266851,\n",
       " 'wasting': 281840,\n",
       " 'away': 22578,\n",
       " 'think': 254767,\n",
       " 'test': 248140,\n",
       " 'thebefore': 250883,\n",
       " 'macd': 150296,\n",
       " 'ondamn': 177535,\n",
       " 'taking': 244483,\n",
       " 'inmins': 128247,\n",
       " 'pity': 190426,\n",
       " 'who': 286984,\n",
       " 'fighiting': 91386,\n",
       " 'against': 5490,\n",
       " 'mms': 158460,\n",
       " 'pitch': 190396,\n",
       " 'atand': 18183,\n",
       " 'bring': 39182,\n",
       " 'totoday': 265788,\n",
       " 'selloff': 222314,\n",
       " 'believe': 29229,\n",
       " 'bounce': 36754,\n",
       " 'better': 31257,\n",
       " 'entry': 82144,\n",
       " 'points': 192195,\n",
       " 'soon': 233066,\n",
       " 'should': 227709,\n",
       " 'trading': 267438,\n",
       " 'technicals': 246313,\n",
       " 'breaks': 38558,\n",
       " 'downthen': 75167,\n",
       " 'straight': 239860,\n",
       " 'massive': 153542,\n",
       " 'dumpto': 77696,\n",
       " 'buying': 44011,\n",
       " 'fang': 89132,\n",
       " 'calls': 46526,\n",
       " 'atfor': 19067,\n",
       " 'earth': 78926,\n",
       " 'toas': 259692,\n",
       " 'suggested': 241930,\n",
       " 'goldman': 106300,\n",
       " 'waterfalls': 282384,\n",
       " 'nine': 169353,\n",
       " 'thirty': 255259,\n",
       " 'bullshit': 41647,\n",
       " 'upgrade': 275134,\n",
       " 'tomorrowboom': 262939,\n",
       " 'town': 266713,\n",
       " 'shorts': 227039,\n",
       " 'harder': 113323,\n",
       " 'open': 179624,\n",
       " 'rip': 212991,\n",
       " 'weeklies': 284086,\n",
       " 'amp': 10156,\n",
       " 'runthese': 216004,\n",
       " 'corporate': 60020,\n",
       " 'crooks': 62588,\n",
       " 'tank': 244780,\n",
       " 'markets': 152962,\n",
       " 'dollars': 72885,\n",
       " 'forheadphonesgtfo': 95977,\n",
       " 'ouchnot': 181857,\n",
       " 'good': 106651,\n",
       " 'newsunemployment': 168004,\n",
       " 'claims': 53212,\n",
       " 'rocketing': 214138,\n",
       " 'higher': 117219,\n",
       " 'waiting': 280361,\n",
       " 'forto': 97000,\n",
       " 'load': 145494,\n",
       " 'huge': 122746,\n",
       " 'printing': 196579,\n",
       " 'might': 156913,\n",
       " 'belowtoday': 30292,\n",
       " 'trump': 269481,\n",
       " 'sued': 241871,\n",
       " 'facebook': 87627,\n",
       " 'blue': 34472,\n",
       " 'stateshmm': 237200,\n",
       " 'does': 72345,\n",
       " 'he': 114537,\n",
       " 'dislike': 71543,\n",
       " 'most': 162291,\n",
       " 'unknowns': 273621,\n",
       " 'everything': 85142,\n",
       " 'doesnt': 72437,\n",
       " 'holdbuying': 119855,\n",
       " 'very': 278495,\n",
       " 'sad': 216324,\n",
       " 'bubble': 40349,\n",
       " 'explosion': 87075,\n",
       " 'spacex': 234076,\n",
       " 'tesla': 247204,\n",
       " 'starship': 236806,\n",
       " 'crashed': 61731,\n",
       " 'exploded': 86988,\n",
       " 'lot': 148506,\n",
       " 'deaths': 67013,\n",
       " 'landing': 139684,\n",
       " 'video': 278708,\n",
       " 'link': 144541,\n",
       " 'ltcommeth': 149610,\n",
       " 'second': 219974,\n",
       " 'shoe': 225811,\n",
       " 'fall': 88581,\n",
       " 'suddenly': 241849,\n",
       " 'bearish': 26332,\n",
       " 'breaksstraight': 38745,\n",
       " 'best': 30903,\n",
       " 'political': 192384,\n",
       " 'unrest': 273904,\n",
       " 'competition': 57683,\n",
       " 'new': 167312,\n",
       " 'listings': 144759,\n",
       " 'kill': 138087,\n",
       " 'term': 246871,\n",
       " 'targetin': 245348,\n",
       " 'near': 166125,\n",
       " 'unfortunately': 273414,\n",
       " 'bishes': 33116,\n",
       " 'en': 81214,\n",
       " 'route': 215029,\n",
       " 'guess': 110348,\n",
       " 'lower': 148944,\n",
       " 'crazy': 62071,\n",
       " 'anymore': 13718,\n",
       " 'sachs': 216287,\n",
       " 'corner': 59839,\n",
       " 'bitches': 33179,\n",
       " 'que': 201924,\n",
       " 'tears': 246142,\n",
       " 'having': 114419,\n",
       " 'seizurepermabulls': 221442,\n",
       " 'heads': 114681,\n",
       " 'explode': 86982,\n",
       " 'tanks': 244948,\n",
       " 'psstcrackable': 198588,\n",
       " 'precious': 194771,\n",
       " 'hose': 121738,\n",
       " 'morning': 161788,\n",
       " 'morecalls': 161283,\n",
       " 'let': 142040,\n",
       " 'rideis': 212445,\n",
       " 'target': 245159,\n",
       " 'cookedwaterfall': 59553,\n",
       " 'millionputs': 157133,\n",
       " 'contracts': 59249,\n",
       " 'closer': 54283,\n",
       " 'collapse': 55643,\n",
       " 'biggest': 32454,\n",
       " 'tell': 246643,\n",
       " 'bonds': 35084,\n",
       " 'dropping': 76405,\n",
       " 'march': 152215,\n",
       " 'vibes': 278632,\n",
       " 'much': 163393,\n",
       " 'fun': 100899,\n",
       " 'todaysorry': 261161,\n",
       " 'fellas': 90886,\n",
       " 'little': 144921,\n",
       " 'dropstay': 76658,\n",
       " 'evalued': 84177,\n",
       " 'overmomentum': 184004,\n",
       " 'gonegoing': 106472,\n",
       " 'tomorrowsell': 263488,\n",
       " 'flashed': 93045,\n",
       " 'share': 224051,\n",
       " 'giant': 104298,\n",
       " 'trapthe': 268187,\n",
       " 'waterfall': 282375,\n",
       " 'continues': 59124,\n",
       " 'lt': 149585,\n",
       " 'absurd': 2071,\n",
       " 'valuation': 277682,\n",
       " 'pe': 187936,\n",
       " 'ludicrous': 149937,\n",
       " 'crashand': 61681,\n",
       " 'would': 291627,\n",
       " 'still': 237783,\n",
       " 'hahahhahaalol': 111935,\n",
       " 'falls': 88814,\n",
       " 'easy': 79123,\n",
       " 'hardly': 113404,\n",
       " 'maybe': 153993,\n",
       " 'shouldnt': 227779,\n",
       " 'balanced': 24629,\n",
       " 'entire': 82067,\n",
       " 'index': 127054,\n",
       " 'follow': 94214,\n",
       " 'happy': 113160,\n",
       " 'closed': 53930,\n",
       " 'tiny': 258972,\n",
       " 'gain': 102026,\n",
       " 'offtank': 175050,\n",
       " 'valued': 277796,\n",
       " 'yikes': 295559,\n",
       " 'weeklys': 284216,\n",
       " 'boys': 37233,\n",
       " 'start': 236818,\n",
       " 'slaying': 230099,\n",
       " 'xmas': 293119,\n",
       " 'shouldve': 227804,\n",
       " 'shorted': 226264,\n",
       " 'after': 4485,\n",
       " 'tweet': 270985,\n",
       " 'wow': 291704,\n",
       " 'eatlunch': 79421,\n",
       " 'zerg': 297188,\n",
       " 'pig': 189937,\n",
       " 'tocan': 260034,\n",
       " 'done': 73098,\n",
       " 'pain': 185641,\n",
       " 'caused': 49497,\n",
       " 'uswe': 277355,\n",
       " 'ground': 109413,\n",
       " 'brutal': 39874,\n",
       " 'head': 114541,\n",
       " 'fake': 88438,\n",
       " 'safe': 216398,\n",
       " 'side': 228337,\n",
       " 'gap': 102734,\n",
       " 'revisiting': 211974,\n",
       " 'indicator': 127170,\n",
       " 'flashingwaterfall': 93054,\n",
       " 'imminent': 125250,\n",
       " 'simply': 228951,\n",
       " 'investment': 130572,\n",
       " 'fomo': 94522,\n",
       " 'running': 215790,\n",
       " 'push': 200120,\n",
       " 'retail': 210940,\n",
       " 'stonks': 239237,\n",
       " 'tend': 246773,\n",
       " 'exponentially': 87110,\n",
       " 'faster': 89520,\n",
       " 'lets': 142095,\n",
       " 'seetoday': 221249,\n",
       " 'knew': 138569,\n",
       " 'rally': 204848,\n",
       " 'amd': 9699,\n",
       " 'first': 92376,\n",
       " 'youre': 296319,\n",
       " 'quietly': 202260,\n",
       " 'dumping': 77428,\n",
       " 'shares': 224247,\n",
       " 'high': 117120,\n",
       " 'thanks': 249073,\n",
       " 'never': 167250,\n",
       " 'breakoutmarket': 38442,\n",
       " 'annihilate': 12573,\n",
       " 'longs': 147144,\n",
       " 'wink': 288050,\n",
       " 'resistance': 210438,\n",
       " 'raise': 204704,\n",
       " 'cash': 48987,\n",
       " 'woww': 292090,\n",
       " 'intoorwayy': 130100,\n",
       " 'potential': 194183,\n",
       " 'year': 293913,\n",
       " 'sink': 229373,\n",
       " 'ship': 225157,\n",
       " 'lolwho': 146727,\n",
       " 'abovei': 1526,\n",
       " 'laughing': 140536,\n",
       " 'them': 252024,\n",
       " 'poor': 192598,\n",
       " 'bullsi': 41726,\n",
       " 'warned': 281238,\n",
       " 'comes': 56088,\n",
       " 'lolmy': 146378,\n",
       " 'job': 135746,\n",
       " 'report': 209892,\n",
       " 'fauci': 89733,\n",
       " 'daythat': 66258,\n",
       " 'holiday': 120872,\n",
       " 'season': 219845,\n",
       " 'worse': 291154,\n",
       " 'stay': 237298,\n",
       " 'or': 180903,\n",
       " 'ampis': 10320,\n",
       " 'alive': 7606,\n",
       " 'rn': 213716,\n",
       " 'spy': 235749,\n",
       " 'feeling': 90774,\n",
       " 'toppy': 264897,\n",
       " 'forpull': 96670,\n",
       " 'backwhen': 23916,\n",
       " 'careful': 48294,\n",
       " 'definetly': 67916,\n",
       " 'small': 230593,\n",
       " 'correction': 60093,\n",
       " 'wreck': 292201,\n",
       " 'vaccines': 277581,\n",
       " 'nasdaq': 165624,\n",
       " 'wedbush': 283244,\n",
       " 'parabolictarget': 186287,\n",
       " 'forfor': 95749,\n",
       " 'found': 97355,\n",
       " 'among': 10104,\n",
       " 'analysts': 10914,\n",
       " 'nearbest': 166151,\n",
       " 'popped': 192806,\n",
       " 'ago': 5838,\n",
       " 'ugly': 271674,\n",
       " 'outdated': 182263,\n",
       " 'seen': 220852,\n",
       " 'thinks': 255114,\n",
       " 'clowns': 54698,\n",
       " 'biden': 32144,\n",
       " 'murder': 163842,\n",
       " 'swear': 243421,\n",
       " 'idiot': 124011,\n",
       " 'whatever': 285848,\n",
       " 'wants': 280983,\n",
       " 'hedge': 115080,\n",
       " 'funds': 101040,\n",
       " 'freeing': 97906,\n",
       " 'ipos': 131537,\n",
       " 'speculative': 234497,\n",
       " 'stocks': 238659,\n",
       " 'breaking': 38069,\n",
       " 'aaple': 174,\n",
       " 'gainon': 102138,\n",
       " 'news': 167541,\n",
       " 'truck': 269286,\n",
       " 'forred': 96715,\n",
       " 'told': 262424,\n",
       " 'guys': 110842,\n",
       " 'pair': 185783,\n",
       " 'ofheadphones': 175190,\n",
       " 'technology': 246360,\n",
       " 'nothing': 170623,\n",
       " 'special': 234373,\n",
       " 'lastminutes': 140006,\n",
       " 'rejected': 208786,\n",
       " 'thetold': 254182,\n",
       " 're': 205768,\n",
       " 'enter': 81944,\n",
       " 'phones': 189584,\n",
       " 'suck': 241633,\n",
       " 'waybreaks': 282623,\n",
       " 'onhold': 178092,\n",
       " 'bearishwill': 26556,\n",
       " 'eod': 82334,\n",
       " 'solid': 232302,\n",
       " 'set': 223533,\n",
       " 'lunch': 150008,\n",
       " 'dumpapple': 77282,\n",
       " 'seesoonthen': 221149,\n",
       " 'starts': 237077,\n",
       " 'quotairpods': 202358,\n",
       " 'maxquot': 153955,\n",
       " 'letting': 142168,\n",
       " 'qs': 201560,\n",
       " 'smh': 230945,\n",
       " 'world': 290780,\n",
       " 'bags': 24361,\n",
       " 'event': 84482,\n",
       " 'earn': 78319,\n",
       " 'save': 217869,\n",
       " 'satisfy': 217796,\n",
       " 'greedy': 108671,\n",
       " 'bankcash': 24956,\n",
       " 'earned': 78323,\n",
       " 'sudden': 241838,\n",
       " 'wait': 280288,\n",
       " 'till': 257894,\n",
       " 'timber': 258148,\n",
       " 'feds': 90685,\n",
       " 'pass': 186678,\n",
       " 'hit': 118521,\n",
       " 'their': 251722,\n",
       " 'qrev': 201547,\n",
       " 'estimate': 83684,\n",
       " 'seeeoy': 220499,\n",
       " 'aapl': 123,\n",
       " 'record': 207466,\n",
       " 'honestly': 121157,\n",
       " 'dick': 69590,\n",
       " 'thing': 254589,\n",
       " 'ppl': 194563,\n",
       " 'advantage': 3964,\n",
       " 'mania': 151683,\n",
       " 'raising': 204782,\n",
       " 'roast': 213840,\n",
       " 'theandcall': 250683,\n",
       " 'holders': 119929,\n",
       " 'stonk': 239216,\n",
       " 'att': 20950,\n",
       " 'everybody': 84846,\n",
       " 'owning': 185225,\n",
       " 'worlds': 290922,\n",
       " 'atm': 19919,\n",
       " 'wasthen': 281823,\n",
       " 'comeswhich': 56204,\n",
       " 'reach': 205785,\n",
       " 'mars': 153331,\n",
       " 'nowdisappointing': 171463,\n",
       " 'everyone': 84997,\n",
       " 'airpods': 6974,\n",
       " 'submarket': 241222,\n",
       " 'cap': 47793,\n",
       " 'phonesthats': 189611,\n",
       " 'saybullshit': 218065,\n",
       " 'magnet': 150837,\n",
       " 'sub': 241012,\n",
       " 'burning': 42458,\n",
       " 'weekly': 284132,\n",
       " 'premiums': 195365,\n",
       " 'subpos': 241300,\n",
       " 'overvalued': 184823,\n",
       " 'couldnt': 60492,\n",
       " 'pivot': 190433,\n",
       " 'toast': 259702,\n",
       " 'youtime': 296703,\n",
       " 'expecting': 86470,\n",
       " 'innovativeover': 128499,\n",
       " 'headphones': 114671,\n",
       " 'flush': 93666,\n",
       " 'clean': 53368,\n",
       " 'pipes': 190326,\n",
       " 'marhet': 152524,\n",
       " 'sampptimes': 217537,\n",
       " 'years': 294228,\n",
       " 'historically': 118412,\n",
       " 'wrecking': 292219,\n",
       " 'disappoint': 71141,\n",
       " 'anotherpoints': 13157,\n",
       " 'rolling': 214488,\n",
       " 'outnasdaq': 182609,\n",
       " 'downby': 74129,\n",
       " 'st': 236408,\n",
       " 'quick': 202053,\n",
       " 'ride': 212386,\n",
       " 'retarded': 211071,\n",
       " 'nonstopapple': 170054,\n",
       " 'steal': 237446,\n",
       " 'pelotons': 188316,\n",
       " 'marketshare': 153012,\n",
       " 'elevator': 80324,\n",
       " 'full': 100831,\n",
       " 'septtop': 223281,\n",
       " 'goodbye': 106694,\n",
       " 'damnwho': 64865,\n",
       " 'buys': 44727,\n",
       " 'headset': 114683,\n",
       " 'ohh': 176209,\n",
       " 'especially': 83562,\n",
       " 'positive': 193519,\n",
       " 'catalyst': 49226,\n",
       " 'foryou': 97318,\n",
       " 'soisnt': 231838,\n",
       " 'youhopes': 296064,\n",
       " 'dreamslooks': 75779,\n",
       " 'stole': 239176,\n",
       " 'alsolook': 8975,\n",
       " 'entering': 81989,\n",
       " 'shes': 224973,\n",
       " 'andisnt': 11636,\n",
       " 'someone': 232677,\n",
       " 'nap': 165528,\n",
       " 'worthbucks': 291308,\n",
       " 'jopes': 136175,\n",
       " 'vaccineirony': 277573,\n",
       " 'demand': 68450,\n",
       " 'supply': 242405,\n",
       " 'ratio': 205514,\n",
       " 'lessso': 142020,\n",
       " 'vaccine': 277555,\n",
       " 'buydont': 43717,\n",
       " 'knucklehead': 138998,\n",
       " 'loading': 145595,\n",
       " 'left': 141597,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def RandomForestModel(stockname):\n",
    "    df = pd.read_csv('sentimentAnalysis_' + stockname  + '.csv', encoding='utf-8')\n",
    "    train, test = train_test_split(df, shuffle=False, test_size=0.2)\n",
    "\n",
    "    sentiment_score_list_train = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'Negative'],  df.loc[date, 'Neutral'], df.loc[date, 'Positive']])\n",
    "        sentiment_score_list_train.append(sentiment_score)\n",
    "        numpy_df_train = np.asarray(sentiment_score_list_train)\n",
    "\n",
    "    sentiment_score_list_test = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'Negative'],  df.loc[date, 'Neutral'], df.loc[date, 'Positive']])\n",
    "        sentiment_score_list_test.append(sentiment_score)\n",
    "        numpy_df_test = np.asarray(sentiment_score_list_test)\n",
    "\n",
    "    y_train = pd.DataFrame(train['Prices'])\n",
    "    y_test = pd.DataFrame(test['Prices'])\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(numpy_df_train, y_train)\n",
    "    prediction, bias, contributions = ti.predict(rf, numpy_df_test)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    plt.figure()\n",
    "    plt.plot(test['Prices'].iloc[:].values)\n",
    "    plt.plot(prediction.flatten())\n",
    "    plt.title('Random Forest predicted prices')\n",
    "    plt.ylabel('Stock Prices')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend(['actual', 'predicted'])\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"RMSE value for Random Forest Model : \")\n",
    "    rmse = sqrt(mean_squared_error(y_test, prediction.flatten()))\n",
    "    print(rmse)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6687c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substring(string, pattern, replacement=''):\n",
    "    \n",
    "    substrings_to_remove = re.findall(pattern, string)\n",
    "    for substring in substrings_to_remove:\n",
    "        string = string.replace(substring, replacement)\n",
    "        \n",
    "    return string\n",
    "\n",
    "def reduce_repeated_chars(string):\n",
    "    new_string = ''\n",
    "    i = 0\n",
    "    while i < len(string):\n",
    "        j = i + 1\n",
    "        while j < len(string) and string[j] == string[i]:\n",
    "            j += 1\n",
    "        new_string += string[i] + (string[i] if j - i >= 2 else '')\n",
    "        i = j\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05411371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making everything lowercase\n",
    "df['body'] = df['body'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ba393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3708f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing patterns\n",
    "\n",
    "website_pattern = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "numbers = '\\d+'\n",
    "usernames = '@[^\\s]+'\n",
    "tickers = '\\$[^\\s]+'\n",
    "extra_spaces = '  +'\n",
    "hashtags = '\\$[^\\s]+'\n",
    "next_lines = '\\\\n'\n",
    "\n",
    "\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, website_pattern))\n",
    "df['body'] = df['body'].apply(lambda x: x.encode('ascii', 'ignore').decode()) #emojis\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, usernames))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, tickers))\n",
    "df['body'] = df['body'].apply(lambda x: reduce_repeated_chars(x))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, numbers))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, hashtags))\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, next_lines, ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "65d0cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~‘’“”1234567890…ðŸ‘‰ðŸ‘ŒðŸ’¦âœ¨✰♡*•˛❤•\n"
     ]
    }
   ],
   "source": [
    "# removing all punctuation\n",
    "\n",
    "punct = punctuation + '‘’“”1234567890…ðŸ‘‰ðŸ‘ŒðŸ’¦âœ¨✰♡*•˛❤•'\n",
    "print(punct)\n",
    "df['body'] = df['body'].apply(lambda x: ''.join([c for c in x if c not in punct]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f52e7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words \n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', \n",
    "             'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
    "             'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', \n",
    "             'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', \n",
    "             'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \n",
    "             'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "             'after', 'to', 'from', 'in', 'out', 'on', 'off', 'again', 'further', 'then', 'once', 'here', 'there', \n",
    "             'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "             'such', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', \n",
    "             'don', 'dont', 'should', 'shouldve', 'now', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', \n",
    "             'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', \n",
    "             'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', \n",
    "             'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt', 'v', 'rn', 'lt', 'y', 'g', 'w', \n",
    "             'wk', 'sp', 'em', 'r', 'vs', 'd', 'ai', 't', 'mm', 'st', 'gt', 'n', 'id', 'p', 'f', 'm', 'b', 'c', \n",
    "             'pe', 'th', 'q', 'x', 'fb', 'ah', 'ill', 'u', 'oh', 'er', 'k', 's', 'im']\n",
    "\n",
    "df['body'] = df['body'].apply(lambda x: ' '.join(x for x in x.split() if x not in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe282d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finishing up by removing extra spaces\n",
    "df['body'] = df['body'].apply(lambda x: remove_substring(x, extra_spaces, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "437e8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with just white spaces\n",
    "df = df[~(df['body'].str.contains('^\\s$', regex=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "22ee82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any rows with just one word wont provide enough context, so we'll remove them as well\n",
    "df = df[(df['body'].str.contains(' '))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ec035d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-15T14:40:00Z</td>\n",
       "      <td>moving fast early</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL Moving fast early!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-15T14:39:57Z</td>\n",
       "      <td>if confirms daily can rip</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL if confirms daily can rip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-15T14:39:42Z</td>\n",
       "      <td>word got outdont miss your chance</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL word got out .... don’t miss your chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-15T14:39:40Z</td>\n",
       "      <td>who sold there weeklies to early lol</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL who sold there weeklies to early lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-15T14:39:36Z</td>\n",
       "      <td>another walk atlets see if it gets gobbled up...</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL another walk at 126 let’s see if it gets...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at                                               body  \\\n",
       "0  2020-12-15T14:40:00Z                                  moving fast early   \n",
       "1  2020-12-15T14:39:57Z                          if confirms daily can rip   \n",
       "2  2020-12-15T14:39:42Z                  word got outdont miss your chance   \n",
       "3  2020-12-15T14:39:40Z               who sold there weeklies to early lol   \n",
       "4  2020-12-15T14:39:36Z   another walk atlets see if it gets gobbled up...   \n",
       "\n",
       "   sentiment                                        raw_content  \n",
       "0          1                           $AAPL Moving fast early!  \n",
       "1          1                    $AAPL if confirms daily can rip  \n",
       "2          1     $AAPL word got out .... don’t miss your chance  \n",
       "3          1         $AAPL who sold there weeklies to early lol  \n",
       "4          1  $AAPL another walk at 126 let’s see if it gets...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "66699b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take ~24 hours\n",
    "# # correct spellings\n",
    "\n",
    "# def spelling_check(text):\n",
    "#     global idx\n",
    "    \n",
    "#     idx += 1\n",
    "    \n",
    "#     if idx % 1e3 == 0: print(idx)\n",
    "        \n",
    "#     try:\n",
    "#         result = str(TextBlob(text).correct())\n",
    "#     except:\n",
    "#         print(f'failed at {idx}')\n",
    "        \n",
    "#     return result\n",
    "\n",
    "# idx = 0\n",
    "# df['body'] = df['body'].apply(lambda x: spelling_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1542ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928816, 4)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsetting a random sample of positive and negative to create a balanced dataset\n",
    "\n",
    "df_negative = df[df['sentiment'] == 0]\n",
    "df_positive = df.query(\"sentiment == 1\").sample(n=len(df_negative))\n",
    "\n",
    "df = pd.concat([df_negative, df_positive])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5f86dd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-12-15T14:38:18Z</td>\n",
       "      <td>going right throughsupport as if it isnt even...</td>\n",
       "      <td>0</td>\n",
       "      <td>$MSFT Going right through 214 support as if it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-12-15T14:23:04Z</td>\n",
       "      <td>nobody gonna buy expensive ass iphones when t...</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL nobody gonna buy expensive ass iPhones w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2020-12-15T14:12:10Z</td>\n",
       "      <td>robinhood peeps gonna be severely disappointe...</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL Robinhood peeps gonna be severely disapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-12-15T13:33:52Z</td>\n",
       "      <td>always dump dump dump</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL always dump dump dump.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2020-12-15T13:30:10Z</td>\n",
       "      <td>why is this turd not going anywhere this is p...</td>\n",
       "      <td>0</td>\n",
       "      <td>$AAPL why is this turd not going anywhere. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593006</th>\n",
       "      <td>2022-01-28T15:12:17Z</td>\n",
       "      <td>soar baby soar</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA soar baby soar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116754</th>\n",
       "      <td>2021-11-09T15:28:11Z</td>\n",
       "      <td>evs getting decimated did brandon shit his pan...</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA $LCID EV&amp;#39;s getting decimated. Did Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911649</th>\n",
       "      <td>2020-02-26T13:57:07Z</td>\n",
       "      <td>apparently bears have short term memory</td>\n",
       "      <td>1</td>\n",
       "      <td>$TSLA Apparently bears have short term memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899134</th>\n",
       "      <td>2022-02-23T18:38:07Z</td>\n",
       "      <td>holy shit i bought more callsmins ago and im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>$SPY holy shit I bought more calls 5 mins ago ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926539</th>\n",
       "      <td>2017-06-09T19:22:12Z</td>\n",
       "      <td>chicken run today fortunately i kept it up an...</td>\n",
       "      <td>1</td>\n",
       "      <td>$NVDA chicken run today, fortunately I kept it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928816 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   created_at  \\\n",
       "14       2020-12-15T14:38:18Z   \n",
       "49       2020-12-15T14:23:04Z   \n",
       "61       2020-12-15T14:12:10Z   \n",
       "103      2020-12-15T13:33:52Z   \n",
       "106      2020-12-15T13:30:10Z   \n",
       "...                       ...   \n",
       "1593006  2022-01-28T15:12:17Z   \n",
       "1116754  2021-11-09T15:28:11Z   \n",
       "1911649  2020-02-26T13:57:07Z   \n",
       "1899134  2022-02-23T18:38:07Z   \n",
       "926539   2017-06-09T19:22:12Z   \n",
       "\n",
       "                                                      body  sentiment  \\\n",
       "14        going right throughsupport as if it isnt even...          0   \n",
       "49        nobody gonna buy expensive ass iphones when t...          0   \n",
       "61        robinhood peeps gonna be severely disappointe...          0   \n",
       "103                                  always dump dump dump          0   \n",
       "106       why is this turd not going anywhere this is p...          0   \n",
       "...                                                    ...        ...   \n",
       "1593006                                     soar baby soar          1   \n",
       "1116754  evs getting decimated did brandon shit his pan...          1   \n",
       "1911649            apparently bears have short term memory          1   \n",
       "1899134   holy shit i bought more callsmins ago and im ...          1   \n",
       "926539    chicken run today fortunately i kept it up an...          1   \n",
       "\n",
       "                                               raw_content  \n",
       "14       $MSFT Going right through 214 support as if it...  \n",
       "49       $AAPL nobody gonna buy expensive ass iPhones w...  \n",
       "61       $AAPL Robinhood peeps gonna be severely disapp...  \n",
       "103                           $AAPL always dump dump dump.  \n",
       "106      $AAPL why is this turd not going anywhere. Thi...  \n",
       "...                                                    ...  \n",
       "1593006                               $TSLA soar baby soar  \n",
       "1116754  $TSLA $LCID EV&#39;s getting decimated. Did Br...  \n",
       "1911649      $TSLA Apparently bears have short term memory  \n",
       "1899134  $SPY holy shit I bought more calls 5 mins ago ...  \n",
       "926539   $NVDA chicken run today, fortunately I kept it...  \n",
       "\n",
       "[928816 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatizing words\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "df['body'] = df['body'].apply(lambda x: lemmatizer.lemmatize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257978b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c65ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/balanced_untokenized_cleaned_stocktwits.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003e5e4",
   "metadata": {},
   "source": [
    "### Lemmatization + Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "257286b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize words\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "df['body'] = df['body'].apply(lambda x: w_tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "216d072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/balanced_tokenized_cleaned_stocktwits.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d19a02",
   "metadata": {},
   "source": [
    "### Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0da991d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "corpus = df['body'].values\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "763c70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an int-mapping dictionary\n",
    "vocab_to_int = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e606e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "padded_sequences = pad_sequences(sequences, 31, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c1788ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(padded_sequences)\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "18515747",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4ca569c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('./data/padded_X.csv', index_label=False)\n",
    "y.to_csv('./data/padded_y.csv', index_label=False)\n",
    "pd.DataFrame([vocab_to_int]).to_csv('./data/vocab_words.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58ee6d",
   "metadata": {},
   "source": [
    "### Create Preprocessing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "581dbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "dct = pd.read_csv('./data/vocab_words.csv').to_dict(orient='records')[0]\n",
    "\n",
    "websites = r'(https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}[-a-zA-Z0-9()@:%_+.~#?&/=]*)'\n",
    "numbers = '\\d+'\n",
    "usernames = '@[^\\s]+'\n",
    "tickers = '\\$[^\\s]+'\n",
    "extra_spaces = '  +'\n",
    "hashtags = '\\$[^\\s]+'\n",
    "next_lines = '\\\\n'\n",
    "\n",
    "punctuation = \"!#$%&'()*+,-./:;<=>?@[\\]^_`{|}~‘’“”1234567890…ðŸ‘‰ðŸ‘ŒðŸ’¦âœ¨✰♡*•˛❤•\" + '\"'\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', \n",
    "             'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \n",
    "             'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', \n",
    "             'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', \n",
    "             'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \n",
    "             'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', \n",
    "             'after', 'to', 'from', 'in', 'out', 'on', 'off', 'again', 'further', 'then', 'once', 'here', 'there', \n",
    "             'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "             'such', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', \n",
    "             'don', 'dont', 'should', 'shouldve', 'now', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', \n",
    "             'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', \n",
    "             'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', \n",
    "             'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt', 'v', 'rn', 'lt', 'y', 'g', 'w', \n",
    "             'wk', 'sp', 'em', 'r', 'vs', 'd', 'ai', 't', 'mm', 'st', 'gt', 'n', 'id', 'p', 'f', 'm', 'b', 'c', \n",
    "             'pe', 'th', 'q', 'x', 'fb', 'ah', 'ill', 'u', 'oh', 'er', 'k', 's', 'im']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e995be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    '''\n",
    "    preprocess the text to input into model\n",
    "    '''\n",
    "    \n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # make texts lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove websites and usernames, if exist\n",
    "    text = re.sub(websites, '', text)\n",
    "    text = re.sub(usernames, '', text)\n",
    "    text = re.sub(numbers, '', text)\n",
    "    text = re.sub(tickers, '', text)\n",
    "    text = re.sub(hashtags, '', text)\n",
    "    text = re.sub(next_lines, '', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = ''.join([x for x in text if x not in punctuation])\n",
    "    \n",
    "    # remove additional characters down to 2\n",
    "    text = re.sub(re.compile(r'(\\w)\\1+'), r'\\1\\1', text)\n",
    "    \n",
    "    # remove stop words\n",
    "    text = ' '.join(text.lower() for text in text.split() if text not in stopwords)\n",
    "    \n",
    "    # remove additional spaces\n",
    "    text = re.sub(extra_spaces, '', text)\n",
    "    \n",
    "    # lemmatize & tokenize\n",
    "    text = [lemmatizer.lemmatize(x) for x in w_tokenizer.tokenize(text)]\n",
    "    \n",
    "    # numericalize\n",
    "    text_int = []\n",
    "    text_int.append([dct[word] for word in text])\n",
    "    \n",
    "    return text_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14e64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc56f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "307dc297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1119,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hello'\n",
    "pad_sequences(preprocess(text), 31, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fcec41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
